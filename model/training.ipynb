{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 362,
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from os import walk\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "source": [
    "# dataset is here: smb://nas-weber01.unisg.ch/data/Nassy/03_Online_Model/features\n",
    "_, _, file_names = next(walk('./dataset'))\n",
    "\n",
    "files = [(name.split('_')[0], name.split('_')[1].split('.')[0], name) for name in file_names]\n",
    "\n",
    "dataset = pd.DataFrame()\n",
    "\n",
    "for (subject_number, task, file_name) in files:\n",
    "    part = pd.read_csv(f'./dataset/{file_name}')\n",
    "    labels = pd.read_csv(f'./labels/{subject_number}.csv', sep=\";\").set_index('task')\n",
    "    rating = float(labels.loc[task]['r'])\n",
    "    part['label'] = int(rating > 3)\n",
    "    part['subject'] = subject_number\n",
    "\n",
    "    dataset = pd.concat([part, dataset])\n",
    "    \n",
    "dataset.tail(80)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   subject task    d_mean  d_median     d_std     e_min     e_max    e_mean  \\\n",
       "0      003   t2  0.220919  0.259452 -0.088826  2.173757  3.732305  2.909432   \n",
       "0      001   t8  0.644607  0.904941 -0.224034  2.798857  5.320766  4.003479   \n",
       "0      003   t5 -0.015260  0.166744  0.346884  2.209762  3.790535  2.972422   \n",
       "0      005   t3  0.087266  0.028885 -0.076025  3.248507  4.961946  4.170758   \n",
       "0      008   t2  0.503004  0.458838 -0.240136  2.819035  5.837738  3.880701   \n",
       "..     ...  ...       ...       ...       ...       ...       ...       ...   \n",
       "0      005   t5  0.628790  0.897065 -0.344902  2.325528  5.208260  3.783169   \n",
       "0      002   t2  0.326944  0.419992 -0.056302  2.622484  4.641601  3.524013   \n",
       "0      002   t4  0.273119  0.244724 -0.150913  2.567246  4.814949  3.697906   \n",
       "0      002   t6  0.469124  0.572494 -0.068472  2.393223  4.824264  3.476828   \n",
       "0      005   t1  0.103125  0.061807 -0.070540  3.184169  5.127730  4.199516   \n",
       "\n",
       "    e_median     e_std  e_peak_count  e_peak_count_pm     b_min     b_max  \\\n",
       "0   2.888242  0.304057           113        30.678733  1.184541  3.732305   \n",
       "0   3.777844  0.522086           147        25.789474  0.622869  5.320766   \n",
       "0   2.975860  0.299366            93        27.623762 -0.104596  3.790535   \n",
       "0   4.238172  0.352659            79        32.689655  0.952023  4.961946   \n",
       "0   3.895067  0.659222           135        37.327189  1.178414  5.837738   \n",
       "..       ...       ...           ...              ...       ...       ...   \n",
       "0   3.531106  0.641257           159        39.750000  0.965752  5.208260   \n",
       "0   3.450530  0.356463           143        30.211268  1.946925  4.641601   \n",
       "0   3.746131  0.478354           102        35.375723  1.032171  4.814949   \n",
       "0   3.365062  0.404711           126        22.500000  0.214578  4.824264   \n",
       "0   4.293928  0.403393            77        30.394737  1.045372  5.127730   \n",
       "\n",
       "      b_mean  b_median     b_std  b_peak_count  b_peak_count_pm  label  \n",
       "0   3.130351  3.147694  0.215231            71        35.500000      0  \n",
       "0   4.648087  4.682785  0.298052            33        16.363636      1  \n",
       "0   2.957162  3.142604  0.646250            72        35.702479      0  \n",
       "0   4.258024  4.267057  0.276634            67        33.223140      0  \n",
       "0   4.383705  4.353905  0.419087           117        58.016529      1  \n",
       "..       ...       ...       ...           ...              ...    ...  \n",
       "0   4.411959  4.428171  0.296355           110        55.000000      1  \n",
       "0   3.850957  3.870521  0.300161            64        32.000000      1  \n",
       "0   3.971025  3.990854  0.327441            83        41.500000      0  \n",
       "0   3.945952  3.937556  0.336239            58        28.760331      1  \n",
       "0   4.302642  4.355734  0.332853            66        33.000000      0  \n",
       "\n",
       "[64 rows x 20 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>task</th>\n",
       "      <th>d_mean</th>\n",
       "      <th>d_median</th>\n",
       "      <th>d_std</th>\n",
       "      <th>e_min</th>\n",
       "      <th>e_max</th>\n",
       "      <th>e_mean</th>\n",
       "      <th>e_median</th>\n",
       "      <th>e_std</th>\n",
       "      <th>e_peak_count</th>\n",
       "      <th>e_peak_count_pm</th>\n",
       "      <th>b_min</th>\n",
       "      <th>b_max</th>\n",
       "      <th>b_mean</th>\n",
       "      <th>b_median</th>\n",
       "      <th>b_std</th>\n",
       "      <th>b_peak_count</th>\n",
       "      <th>b_peak_count_pm</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003</td>\n",
       "      <td>t2</td>\n",
       "      <td>0.220919</td>\n",
       "      <td>0.259452</td>\n",
       "      <td>-0.088826</td>\n",
       "      <td>2.173757</td>\n",
       "      <td>3.732305</td>\n",
       "      <td>2.909432</td>\n",
       "      <td>2.888242</td>\n",
       "      <td>0.304057</td>\n",
       "      <td>113</td>\n",
       "      <td>30.678733</td>\n",
       "      <td>1.184541</td>\n",
       "      <td>3.732305</td>\n",
       "      <td>3.130351</td>\n",
       "      <td>3.147694</td>\n",
       "      <td>0.215231</td>\n",
       "      <td>71</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001</td>\n",
       "      <td>t8</td>\n",
       "      <td>0.644607</td>\n",
       "      <td>0.904941</td>\n",
       "      <td>-0.224034</td>\n",
       "      <td>2.798857</td>\n",
       "      <td>5.320766</td>\n",
       "      <td>4.003479</td>\n",
       "      <td>3.777844</td>\n",
       "      <td>0.522086</td>\n",
       "      <td>147</td>\n",
       "      <td>25.789474</td>\n",
       "      <td>0.622869</td>\n",
       "      <td>5.320766</td>\n",
       "      <td>4.648087</td>\n",
       "      <td>4.682785</td>\n",
       "      <td>0.298052</td>\n",
       "      <td>33</td>\n",
       "      <td>16.363636</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003</td>\n",
       "      <td>t5</td>\n",
       "      <td>-0.015260</td>\n",
       "      <td>0.166744</td>\n",
       "      <td>0.346884</td>\n",
       "      <td>2.209762</td>\n",
       "      <td>3.790535</td>\n",
       "      <td>2.972422</td>\n",
       "      <td>2.975860</td>\n",
       "      <td>0.299366</td>\n",
       "      <td>93</td>\n",
       "      <td>27.623762</td>\n",
       "      <td>-0.104596</td>\n",
       "      <td>3.790535</td>\n",
       "      <td>2.957162</td>\n",
       "      <td>3.142604</td>\n",
       "      <td>0.646250</td>\n",
       "      <td>72</td>\n",
       "      <td>35.702479</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>005</td>\n",
       "      <td>t3</td>\n",
       "      <td>0.087266</td>\n",
       "      <td>0.028885</td>\n",
       "      <td>-0.076025</td>\n",
       "      <td>3.248507</td>\n",
       "      <td>4.961946</td>\n",
       "      <td>4.170758</td>\n",
       "      <td>4.238172</td>\n",
       "      <td>0.352659</td>\n",
       "      <td>79</td>\n",
       "      <td>32.689655</td>\n",
       "      <td>0.952023</td>\n",
       "      <td>4.961946</td>\n",
       "      <td>4.258024</td>\n",
       "      <td>4.267057</td>\n",
       "      <td>0.276634</td>\n",
       "      <td>67</td>\n",
       "      <td>33.223140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>008</td>\n",
       "      <td>t2</td>\n",
       "      <td>0.503004</td>\n",
       "      <td>0.458838</td>\n",
       "      <td>-0.240136</td>\n",
       "      <td>2.819035</td>\n",
       "      <td>5.837738</td>\n",
       "      <td>3.880701</td>\n",
       "      <td>3.895067</td>\n",
       "      <td>0.659222</td>\n",
       "      <td>135</td>\n",
       "      <td>37.327189</td>\n",
       "      <td>1.178414</td>\n",
       "      <td>5.837738</td>\n",
       "      <td>4.383705</td>\n",
       "      <td>4.353905</td>\n",
       "      <td>0.419087</td>\n",
       "      <td>117</td>\n",
       "      <td>58.016529</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>005</td>\n",
       "      <td>t5</td>\n",
       "      <td>0.628790</td>\n",
       "      <td>0.897065</td>\n",
       "      <td>-0.344902</td>\n",
       "      <td>2.325528</td>\n",
       "      <td>5.208260</td>\n",
       "      <td>3.783169</td>\n",
       "      <td>3.531106</td>\n",
       "      <td>0.641257</td>\n",
       "      <td>159</td>\n",
       "      <td>39.750000</td>\n",
       "      <td>0.965752</td>\n",
       "      <td>5.208260</td>\n",
       "      <td>4.411959</td>\n",
       "      <td>4.428171</td>\n",
       "      <td>0.296355</td>\n",
       "      <td>110</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002</td>\n",
       "      <td>t2</td>\n",
       "      <td>0.326944</td>\n",
       "      <td>0.419992</td>\n",
       "      <td>-0.056302</td>\n",
       "      <td>2.622484</td>\n",
       "      <td>4.641601</td>\n",
       "      <td>3.524013</td>\n",
       "      <td>3.450530</td>\n",
       "      <td>0.356463</td>\n",
       "      <td>143</td>\n",
       "      <td>30.211268</td>\n",
       "      <td>1.946925</td>\n",
       "      <td>4.641601</td>\n",
       "      <td>3.850957</td>\n",
       "      <td>3.870521</td>\n",
       "      <td>0.300161</td>\n",
       "      <td>64</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002</td>\n",
       "      <td>t4</td>\n",
       "      <td>0.273119</td>\n",
       "      <td>0.244724</td>\n",
       "      <td>-0.150913</td>\n",
       "      <td>2.567246</td>\n",
       "      <td>4.814949</td>\n",
       "      <td>3.697906</td>\n",
       "      <td>3.746131</td>\n",
       "      <td>0.478354</td>\n",
       "      <td>102</td>\n",
       "      <td>35.375723</td>\n",
       "      <td>1.032171</td>\n",
       "      <td>4.814949</td>\n",
       "      <td>3.971025</td>\n",
       "      <td>3.990854</td>\n",
       "      <td>0.327441</td>\n",
       "      <td>83</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002</td>\n",
       "      <td>t6</td>\n",
       "      <td>0.469124</td>\n",
       "      <td>0.572494</td>\n",
       "      <td>-0.068472</td>\n",
       "      <td>2.393223</td>\n",
       "      <td>4.824264</td>\n",
       "      <td>3.476828</td>\n",
       "      <td>3.365062</td>\n",
       "      <td>0.404711</td>\n",
       "      <td>126</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.214578</td>\n",
       "      <td>4.824264</td>\n",
       "      <td>3.945952</td>\n",
       "      <td>3.937556</td>\n",
       "      <td>0.336239</td>\n",
       "      <td>58</td>\n",
       "      <td>28.760331</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>005</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.103125</td>\n",
       "      <td>0.061807</td>\n",
       "      <td>-0.070540</td>\n",
       "      <td>3.184169</td>\n",
       "      <td>5.127730</td>\n",
       "      <td>4.199516</td>\n",
       "      <td>4.293928</td>\n",
       "      <td>0.403393</td>\n",
       "      <td>77</td>\n",
       "      <td>30.394737</td>\n",
       "      <td>1.045372</td>\n",
       "      <td>5.127730</td>\n",
       "      <td>4.302642</td>\n",
       "      <td>4.355734</td>\n",
       "      <td>0.332853</td>\n",
       "      <td>66</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 20 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 379
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "TRAIN_FILTER = (~(dataset['task'] == 't1') & ~(dataset['subject'] == '005'))\n",
    "#TRAIN_FILTER = ~(dataset['subject'] == '008')\n",
    "\n",
    "fields = ['d_mean', 'd_median', 'd_std', 'd_lhipa', 'd_max', 'd_min']\n",
    "data_train = dataset[~TRAIN_FILTER].drop(['subject', 'task', 'label'], axis=1)[fields].to_numpy()\n",
    "data_test = dataset[TRAIN_FILTER].drop(['subject', 'task', 'label'], axis=1)[fields].to_numpy()\n",
    "\n",
    "targets_train = dataset[~TRAIN_FILTER]['label'].to_numpy()\n",
    "targets_test = dataset[TRAIN_FILTER]['label'].to_numpy()\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-1-619fc284e1f8>, line 7)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-619fc284e1f8>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    data_train = dataset[~TRAIN_FILTER].drop(['subject', 'task', 'label'], axis=1)[fields].to_numpy()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "source": [
    "# test shapes\n",
    "print(data_train.shape)\n",
    "print(targets_train.shape)\n",
    "print(data_test.shape)\n",
    "print(targets_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(15, 17)\n",
      "(15,)\n",
      "(49, 17)\n",
      "(49,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "source": [
    "## wrap data in dataset\n",
    "# cast to tensor\n",
    "data_train = torch.tensor(data_train).float()\n",
    "targets_train = torch.tensor(targets_train).long()#.unsqueeze(dim=-1)\n",
    "data_test = torch.tensor(data_test).float()\n",
    "targets_test = torch.tensor(targets_test).long()#.unsqueeze(dim=-1)\n",
    "# wrap in dataset class\n",
    "dataset_train = torch.utils.data.TensorDataset(data_train, targets_train)\n",
    "dataset_test = torch.utils.data.TensorDataset(data_test, targets_test)\n",
    "# create dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(dataset_train, batch_size=10,shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(dataset_test, batch_size=10,shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "source": [
    "## create model\n",
    "class NN(torch.nn.Module):\n",
    "    def __init__(self, input_dimension,number_of_target_classes):\n",
    "        super().__init__()\n",
    "        # stack layers\n",
    "        self.module_list = torch.nn.ModuleList()\n",
    "        ## stacks contain of linear + nonlinear layers\n",
    "        self.module_list.append(torch.nn.Linear(input_dimension,200))\n",
    "        self.module_list.append(torch.nn.Tanh())\n",
    "        #\n",
    "        self.module_list.append(torch.nn.Linear(200,200))\n",
    "        self.module_list.append(torch.nn.Tanh())\n",
    "        #\n",
    "        self.module_list.append(torch.nn.Linear(200,150))\n",
    "        self.module_list.append(torch.nn.Tanh())\n",
    "        # map to output layer\n",
    "        self.module_list.append(torch.nn.Linear(150,number_of_target_classes))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        for module in self.module_list:\n",
    "            x = module(x)\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "source": [
    "#instanciate model\n",
    "model = NN(17,2)\n",
    "#model.to(device)\n",
    "# test forward pass\n",
    "model(data_train[:10])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.2331, 0.2607],\n",
       "        [0.2067, 0.3339],\n",
       "        [0.2335, 0.2707],\n",
       "        [0.1816, 0.3514],\n",
       "        [0.2035, 0.3124],\n",
       "        [0.2302, 0.3056],\n",
       "        [0.2303, 0.3053],\n",
       "        [0.2299, 0.3059],\n",
       "        [0.1997, 0.3367],\n",
       "        [0.2010, 0.3276]], grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 384
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "source": [
    "# def criterion and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.01)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "source": [
    "# train\n",
    "for epoch in range(2000):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, targets = data\n",
    "        inputs.to(device)\n",
    "        targets.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        # \n",
    "        targets = targets.squeeze()\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 0:    # print every 2000 mini-batches\n",
    "            #print(\"Training loss {} Steps: {}\".format(running_loss / 1000, epoch * len(trainloader) + i))\n",
    "            running_loss = 0.0\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "new task\n",
    "new participant\n",
    "new task new participant"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# iterate over test data\n",
    "for inputs, labels in testloader:\n",
    "        output = model(inputs) # Feed Network\n",
    "\n",
    "        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "        y_pred.extend(output) # Save Prediction\n",
    "        \n",
    "        labels = labels.data.cpu().numpy()\n",
    "        y_true.extend(labels) # Save Truth\n",
    "\n",
    "# constant for classes\n",
    "classes = ('LOW', 'HIGH')\n",
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix), index = [i for i in classes], columns = [i for i in classes])\n",
    "plt.figure(figsize = (12,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.savefig('without-task-1-subject-5.png')"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "source": [
    "torch.save(model.state_dict(), './export/torch')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "source": [
    "dataset"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   subject task    d_mean  d_median     d_std     e_min     e_max    e_mean  \\\n",
       "0      003   t2  0.220919  0.259452 -0.088826  2.173757  3.732305  2.909432   \n",
       "0      001   t8  0.644607  0.904941 -0.224034  2.798857  5.320766  4.003479   \n",
       "0      003   t5 -0.015260  0.166744  0.346884  2.209762  3.790535  2.972422   \n",
       "0      005   t3  0.087266  0.028885 -0.076025  3.248507  4.961946  4.170758   \n",
       "0      008   t2  0.503004  0.458838 -0.240136  2.819035  5.837738  3.880701   \n",
       "..     ...  ...       ...       ...       ...       ...       ...       ...   \n",
       "0      005   t5  0.628790  0.897065 -0.344902  2.325528  5.208260  3.783169   \n",
       "0      002   t2  0.326944  0.419992 -0.056302  2.622484  4.641601  3.524013   \n",
       "0      002   t4  0.273119  0.244724 -0.150913  2.567246  4.814949  3.697906   \n",
       "0      002   t6  0.469124  0.572494 -0.068472  2.393223  4.824264  3.476828   \n",
       "0      005   t1  0.103125  0.061807 -0.070540  3.184169  5.127730  4.199516   \n",
       "\n",
       "    e_median     e_std  e_peak_count  e_peak_count_pm     b_min     b_max  \\\n",
       "0   2.888242  0.304057           113        30.678733  1.184541  3.732305   \n",
       "0   3.777844  0.522086           147        25.789474  0.622869  5.320766   \n",
       "0   2.975860  0.299366            93        27.623762 -0.104596  3.790535   \n",
       "0   4.238172  0.352659            79        32.689655  0.952023  4.961946   \n",
       "0   3.895067  0.659222           135        37.327189  1.178414  5.837738   \n",
       "..       ...       ...           ...              ...       ...       ...   \n",
       "0   3.531106  0.641257           159        39.750000  0.965752  5.208260   \n",
       "0   3.450530  0.356463           143        30.211268  1.946925  4.641601   \n",
       "0   3.746131  0.478354           102        35.375723  1.032171  4.814949   \n",
       "0   3.365062  0.404711           126        22.500000  0.214578  4.824264   \n",
       "0   4.293928  0.403393            77        30.394737  1.045372  5.127730   \n",
       "\n",
       "      b_mean  b_median     b_std  b_peak_count  b_peak_count_pm  label  \n",
       "0   3.130351  3.147694  0.215231            71        35.500000      0  \n",
       "0   4.648087  4.682785  0.298052            33        16.363636      1  \n",
       "0   2.957162  3.142604  0.646250            72        35.702479      0  \n",
       "0   4.258024  4.267057  0.276634            67        33.223140      0  \n",
       "0   4.383705  4.353905  0.419087           117        58.016529      1  \n",
       "..       ...       ...       ...           ...              ...    ...  \n",
       "0   4.411959  4.428171  0.296355           110        55.000000      1  \n",
       "0   3.850957  3.870521  0.300161            64        32.000000      1  \n",
       "0   3.971025  3.990854  0.327441            83        41.500000      0  \n",
       "0   3.945952  3.937556  0.336239            58        28.760331      1  \n",
       "0   4.302642  4.355734  0.332853            66        33.000000      0  \n",
       "\n",
       "[64 rows x 20 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>task</th>\n",
       "      <th>d_mean</th>\n",
       "      <th>d_median</th>\n",
       "      <th>d_std</th>\n",
       "      <th>e_min</th>\n",
       "      <th>e_max</th>\n",
       "      <th>e_mean</th>\n",
       "      <th>e_median</th>\n",
       "      <th>e_std</th>\n",
       "      <th>e_peak_count</th>\n",
       "      <th>e_peak_count_pm</th>\n",
       "      <th>b_min</th>\n",
       "      <th>b_max</th>\n",
       "      <th>b_mean</th>\n",
       "      <th>b_median</th>\n",
       "      <th>b_std</th>\n",
       "      <th>b_peak_count</th>\n",
       "      <th>b_peak_count_pm</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003</td>\n",
       "      <td>t2</td>\n",
       "      <td>0.220919</td>\n",
       "      <td>0.259452</td>\n",
       "      <td>-0.088826</td>\n",
       "      <td>2.173757</td>\n",
       "      <td>3.732305</td>\n",
       "      <td>2.909432</td>\n",
       "      <td>2.888242</td>\n",
       "      <td>0.304057</td>\n",
       "      <td>113</td>\n",
       "      <td>30.678733</td>\n",
       "      <td>1.184541</td>\n",
       "      <td>3.732305</td>\n",
       "      <td>3.130351</td>\n",
       "      <td>3.147694</td>\n",
       "      <td>0.215231</td>\n",
       "      <td>71</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001</td>\n",
       "      <td>t8</td>\n",
       "      <td>0.644607</td>\n",
       "      <td>0.904941</td>\n",
       "      <td>-0.224034</td>\n",
       "      <td>2.798857</td>\n",
       "      <td>5.320766</td>\n",
       "      <td>4.003479</td>\n",
       "      <td>3.777844</td>\n",
       "      <td>0.522086</td>\n",
       "      <td>147</td>\n",
       "      <td>25.789474</td>\n",
       "      <td>0.622869</td>\n",
       "      <td>5.320766</td>\n",
       "      <td>4.648087</td>\n",
       "      <td>4.682785</td>\n",
       "      <td>0.298052</td>\n",
       "      <td>33</td>\n",
       "      <td>16.363636</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003</td>\n",
       "      <td>t5</td>\n",
       "      <td>-0.015260</td>\n",
       "      <td>0.166744</td>\n",
       "      <td>0.346884</td>\n",
       "      <td>2.209762</td>\n",
       "      <td>3.790535</td>\n",
       "      <td>2.972422</td>\n",
       "      <td>2.975860</td>\n",
       "      <td>0.299366</td>\n",
       "      <td>93</td>\n",
       "      <td>27.623762</td>\n",
       "      <td>-0.104596</td>\n",
       "      <td>3.790535</td>\n",
       "      <td>2.957162</td>\n",
       "      <td>3.142604</td>\n",
       "      <td>0.646250</td>\n",
       "      <td>72</td>\n",
       "      <td>35.702479</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>005</td>\n",
       "      <td>t3</td>\n",
       "      <td>0.087266</td>\n",
       "      <td>0.028885</td>\n",
       "      <td>-0.076025</td>\n",
       "      <td>3.248507</td>\n",
       "      <td>4.961946</td>\n",
       "      <td>4.170758</td>\n",
       "      <td>4.238172</td>\n",
       "      <td>0.352659</td>\n",
       "      <td>79</td>\n",
       "      <td>32.689655</td>\n",
       "      <td>0.952023</td>\n",
       "      <td>4.961946</td>\n",
       "      <td>4.258024</td>\n",
       "      <td>4.267057</td>\n",
       "      <td>0.276634</td>\n",
       "      <td>67</td>\n",
       "      <td>33.223140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>008</td>\n",
       "      <td>t2</td>\n",
       "      <td>0.503004</td>\n",
       "      <td>0.458838</td>\n",
       "      <td>-0.240136</td>\n",
       "      <td>2.819035</td>\n",
       "      <td>5.837738</td>\n",
       "      <td>3.880701</td>\n",
       "      <td>3.895067</td>\n",
       "      <td>0.659222</td>\n",
       "      <td>135</td>\n",
       "      <td>37.327189</td>\n",
       "      <td>1.178414</td>\n",
       "      <td>5.837738</td>\n",
       "      <td>4.383705</td>\n",
       "      <td>4.353905</td>\n",
       "      <td>0.419087</td>\n",
       "      <td>117</td>\n",
       "      <td>58.016529</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>005</td>\n",
       "      <td>t5</td>\n",
       "      <td>0.628790</td>\n",
       "      <td>0.897065</td>\n",
       "      <td>-0.344902</td>\n",
       "      <td>2.325528</td>\n",
       "      <td>5.208260</td>\n",
       "      <td>3.783169</td>\n",
       "      <td>3.531106</td>\n",
       "      <td>0.641257</td>\n",
       "      <td>159</td>\n",
       "      <td>39.750000</td>\n",
       "      <td>0.965752</td>\n",
       "      <td>5.208260</td>\n",
       "      <td>4.411959</td>\n",
       "      <td>4.428171</td>\n",
       "      <td>0.296355</td>\n",
       "      <td>110</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002</td>\n",
       "      <td>t2</td>\n",
       "      <td>0.326944</td>\n",
       "      <td>0.419992</td>\n",
       "      <td>-0.056302</td>\n",
       "      <td>2.622484</td>\n",
       "      <td>4.641601</td>\n",
       "      <td>3.524013</td>\n",
       "      <td>3.450530</td>\n",
       "      <td>0.356463</td>\n",
       "      <td>143</td>\n",
       "      <td>30.211268</td>\n",
       "      <td>1.946925</td>\n",
       "      <td>4.641601</td>\n",
       "      <td>3.850957</td>\n",
       "      <td>3.870521</td>\n",
       "      <td>0.300161</td>\n",
       "      <td>64</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002</td>\n",
       "      <td>t4</td>\n",
       "      <td>0.273119</td>\n",
       "      <td>0.244724</td>\n",
       "      <td>-0.150913</td>\n",
       "      <td>2.567246</td>\n",
       "      <td>4.814949</td>\n",
       "      <td>3.697906</td>\n",
       "      <td>3.746131</td>\n",
       "      <td>0.478354</td>\n",
       "      <td>102</td>\n",
       "      <td>35.375723</td>\n",
       "      <td>1.032171</td>\n",
       "      <td>4.814949</td>\n",
       "      <td>3.971025</td>\n",
       "      <td>3.990854</td>\n",
       "      <td>0.327441</td>\n",
       "      <td>83</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002</td>\n",
       "      <td>t6</td>\n",
       "      <td>0.469124</td>\n",
       "      <td>0.572494</td>\n",
       "      <td>-0.068472</td>\n",
       "      <td>2.393223</td>\n",
       "      <td>4.824264</td>\n",
       "      <td>3.476828</td>\n",
       "      <td>3.365062</td>\n",
       "      <td>0.404711</td>\n",
       "      <td>126</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.214578</td>\n",
       "      <td>4.824264</td>\n",
       "      <td>3.945952</td>\n",
       "      <td>3.937556</td>\n",
       "      <td>0.336239</td>\n",
       "      <td>58</td>\n",
       "      <td>28.760331</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>005</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.103125</td>\n",
       "      <td>0.061807</td>\n",
       "      <td>-0.070540</td>\n",
       "      <td>3.184169</td>\n",
       "      <td>5.127730</td>\n",
       "      <td>4.199516</td>\n",
       "      <td>4.293928</td>\n",
       "      <td>0.403393</td>\n",
       "      <td>77</td>\n",
       "      <td>30.394737</td>\n",
       "      <td>1.045372</td>\n",
       "      <td>5.127730</td>\n",
       "      <td>4.302642</td>\n",
       "      <td>4.355734</td>\n",
       "      <td>0.332853</td>\n",
       "      <td>66</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 20 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 389
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "source": [
    "\n",
    "right = 0\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    device = torch.device('cuda')\n",
    "    model2 = NN(17,2)\n",
    "    model2.load_state_dict(torch.load('./export/torch', map_location=device))\n",
    "    model2.eval()\n",
    "\n",
    "    for index in list(range(1, 64)):\n",
    "        data_to_predict = dataset.drop(['subject', 'task', 'label'], axis=1).to_numpy()[index]\n",
    "\n",
    "        prediction = model2(torch.from_numpy(data_to_predict).float())\n",
    "        predicted_class = np.argmax(prediction)\n",
    "        print(prediction, predicted_class, dataset.iloc[index]['label'], dataset.iloc[index]['subject'], dataset.iloc[index]['task'])\n",
    "        right += 1 if predicted_class == dataset.iloc[index]['label'] else 0\n",
    "        count += 1\n",
    "\n",
    "print(right, count, right/count)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([ 0.8329, -0.5150]) tensor(0) 1 001 t8\n",
      "tensor([ 1.0961, -0.7771]) tensor(0) 0 003 t5\n",
      "tensor([ 1.3356, -1.1660]) tensor(0) 0 005 t3\n",
      "tensor([ 1.1652, -0.7802]) tensor(0) 1 008 t2\n",
      "tensor([ 0.8349, -0.5191]) tensor(0) 1 001 t5\n",
      "tensor([-0.0961,  0.5733]) tensor(1) 1 008 t7\n",
      "tensor([ 0.6584, -0.2430]) tensor(0) 1 002 t5\n",
      "tensor([0.0086, 0.4006]) tensor(1) 1 005 t7\n",
      "tensor([ 1.2800, -1.0658]) tensor(0) 0 003 t3\n",
      "tensor([-0.1035,  0.6107]) tensor(1) 1 002 t8\n",
      "tensor([ 1.3336, -1.1650]) tensor(0) 0 008 t1\n",
      "tensor([ 0.6026, -0.0416]) tensor(0) 0 003 t6\n",
      "tensor([0.3971, 0.0152]) tensor(0) 0 004 t8\n",
      "tensor([0.3090, 0.0881]) tensor(0) 0 006 t7\n",
      "tensor([ 0.7888, -0.4142]) tensor(0) 1 001 t7\n",
      "tensor([ 1.2458, -1.0488]) tensor(0) 0 007 t1\n",
      "tensor([ 1.3510, -1.2073]) tensor(0) 0 005 t4\n",
      "tensor([ 0.5717, -0.3057]) tensor(0) 0 006 t3\n",
      "tensor([ 1.2873, -1.0509]) tensor(0) 0 004 t3\n",
      "tensor([ 1.2730, -1.0160]) tensor(0) 0 008 t4\n",
      "tensor([0.0221, 0.4103]) tensor(1) 0 006 t8\n",
      "tensor([ 0.8001, -0.4433]) tensor(0) 0 001 t1\n",
      "tensor([ 0.6511, -0.1100]) tensor(0) 1 007 t6\n",
      "tensor([0.1900, 0.0858]) tensor(0) 0 001 t3\n",
      "tensor([ 0.6992, -0.3478]) tensor(0) 0 006 t2\n",
      "tensor([ 0.6467, -0.3486]) tensor(0) 0 006 t5\n",
      "tensor([ 1.2459, -1.0610]) tensor(0) 1 007 t4\n",
      "tensor([ 0.9767, -0.6971]) tensor(0) 0 002 t3\n",
      "tensor([ 1.2691, -1.0176]) tensor(0) 1 007 t3\n",
      "tensor([-0.0998,  0.5834]) tensor(1) 1 008 t6\n",
      "tensor([0.1037, 0.1565]) tensor(1) 0 004 t1\n",
      "tensor([ 1.2586, -0.9744]) tensor(0) 0 004 t4\n",
      "tensor([ 0.3381, -0.0798]) tensor(0) 0 004 t7\n",
      "tensor([-0.0290,  0.4339]) tensor(1) 1 005 t8\n",
      "tensor([ 1.2757, -1.0221]) tensor(0) 0 008 t3\n",
      "tensor([ 0.9050, -0.4826]) tensor(0) 0 003 t7\n",
      "tensor([0.2023, 0.1491]) tensor(0) 0 004 t5\n",
      "tensor([ 1.2243, -0.9188]) tensor(0) 0 003 t4\n",
      "tensor([0.3381, 0.0245]) tensor(0) 0 006 t6\n",
      "tensor([ 1.1351, -0.8293]) tensor(0) 1 002 t7\n",
      "tensor([ 0.8223, -0.4902]) tensor(0) 0 004 t2\n",
      "tensor([ 0.6780, -0.1687]) tensor(0) 1 007 t8\n",
      "tensor([-0.1169,  0.6238]) tensor(1) 1 005 t2\n",
      "tensor([ 1.2010, -0.8543]) tensor(0) 1 008 t5\n",
      "tensor([ 1.2592, -1.0998]) tensor(0) 0 003 t1\n",
      "tensor([-0.1105,  0.6212]) tensor(1) 1 008 t8\n",
      "tensor([ 1.0170, -0.8052]) tensor(0) 1 007 t5\n",
      "tensor([-0.1055,  0.5936]) tensor(1) 1 005 t6\n",
      "tensor([0.3318, 0.0408]) tensor(0) 0 007 t7\n",
      "tensor([ 0.8335, -0.5158]) tensor(0) 1 001 t6\n",
      "tensor([ 1.2514, -1.0089]) tensor(0) 0 002 t1\n",
      "tensor([ 0.6551, -0.1188]) tensor(0) 1 003 t8\n",
      "tensor([ 0.6325, -0.2269]) tensor(0) 0 001 t2\n",
      "tensor([ 1.1778, -0.8870]) tensor(0) 0 006 t4\n",
      "tensor([ 0.8341, -0.5171]) tensor(0) 1 004 t6\n",
      "tensor([ 0.6483, -0.1375]) tensor(0) 0 007 t2\n",
      "tensor([ 0.4157, -0.0853]) tensor(0) 0 001 t4\n",
      "tensor([0.0147, 0.3930]) tensor(1) 0 006 t1\n",
      "tensor([-0.1235,  0.6342]) tensor(1) 1 005 t5\n",
      "tensor([ 0.4055, -0.0535]) tensor(0) 1 002 t2\n",
      "tensor([ 1.2540, -0.9727]) tensor(0) 0 002 t4\n",
      "tensor([0.3934, 0.0629]) tensor(0) 1 002 t6\n",
      "tensor([ 1.3026, -1.0855]) tensor(0) 0 005 t1\n",
      "43 63 0.6825396825396826\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "source": [
    "model# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model's state_dict:\n",
      "module_list.0.weight \t torch.Size([20, 17])\n",
      "module_list.0.bias \t torch.Size([20])\n",
      "module_list.2.weight \t torch.Size([10, 20])\n",
      "module_list.2.bias \t torch.Size([10])\n",
      "module_list.4.weight \t torch.Size([2, 10])\n",
      "module_list.4.bias \t torch.Size([2])\n",
      "Optimizer's state_dict:\n",
      "state \t {0: {'momentum_buffer': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 3.2844e-06,  3.0065e-06, -1.3487e-06,  6.3948e-05,  1.2382e-04,\n",
      "          9.8575e-05,  9.8825e-05,  8.9952e-06,  2.0307e-03,  6.7161e-04,\n",
      "          1.5445e-05,  1.2355e-04,  1.0186e-04,  1.0183e-04,  7.6465e-06,\n",
      "          1.5025e-03,  7.4638e-04],\n",
      "        [ 5.7983e-03,  7.6873e-03, -3.8582e-03, -3.3821e-02, -6.8565e-02,\n",
      "         -6.4970e-02, -6.6553e-02, -1.8093e-04, -2.7641e-01, -2.5320e-01,\n",
      "          2.5818e-02, -6.7829e-02, -5.9171e-02, -5.8865e-02, -4.0391e-03,\n",
      "         -6.8325e-01, -3.3918e-01],\n",
      "        [-3.3654e-06, -4.0753e-06,  1.2578e-06, -3.4008e-05, -7.7573e-05,\n",
      "         -5.9610e-05, -5.8596e-05, -6.0214e-06, -1.4628e-03, -4.0830e-04,\n",
      "         -6.9503e-06, -7.7329e-05, -6.2976e-05, -6.2672e-05, -4.7636e-06,\n",
      "         -9.8780e-04, -4.9048e-04],\n",
      "        [-6.5453e-11, -8.3503e-11,  2.2322e-11, -5.1763e-10, -1.3237e-09,\n",
      "         -9.9884e-10, -9.7166e-10, -1.0307e-10, -2.6103e-08, -6.6744e-09,\n",
      "         -8.2334e-11, -1.3185e-09, -1.0643e-09, -1.0552e-09, -8.0751e-11,\n",
      "         -1.6692e-08, -8.2777e-09],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-6.6824e-07, -3.5559e-07,  4.8959e-07, -2.1636e-05, -3.4323e-05,\n",
      "         -2.8330e-05, -2.8904e-05, -2.6186e-06, -5.2581e-04, -2.1035e-04,\n",
      "         -6.8442e-06, -3.4323e-05, -2.8999e-05, -2.9260e-05, -2.1290e-06,\n",
      "         -4.4839e-04, -2.2359e-04],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-1.4696e-07, -1.1280e-07,  9.0038e-08, -3.5830e-06, -6.0391e-06,\n",
      "         -4.9272e-06, -4.9855e-06, -4.5653e-07, -9.7837e-05, -3.6395e-05,\n",
      "         -1.0519e-06, -6.0349e-06, -5.0742e-06, -5.0983e-06, -3.6649e-07,\n",
      "         -7.8927e-05, -3.9278e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 1.9980e-04,  2.4606e-04, -9.7010e-05,  8.0157e-04,  1.9283e-03,\n",
      "          1.3097e-03,  1.2546e-03,  2.1786e-04,  4.9439e-02,  1.1468e-02,\n",
      "          6.4312e-04,  1.9297e-03,  1.5095e-03,  1.5007e-03,  1.2085e-04,\n",
      "          2.5975e-02,  1.2880e-02],\n",
      "        [-1.4586e-04, -1.7878e-04,  7.3284e-05, -5.2244e-04, -1.2355e-03,\n",
      "         -8.1429e-04, -7.7662e-04, -1.5130e-04, -3.3622e-02, -7.6534e-03,\n",
      "         -5.0298e-04, -1.2378e-03, -9.6015e-04, -9.5540e-04, -7.8018e-05,\n",
      "         -1.6916e-02, -8.3879e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-1.9348e-07, -9.8395e-08,  1.4505e-07, -6.3704e-06, -1.0056e-05,\n",
      "         -8.3204e-06, -8.4841e-06, -7.6005e-07, -1.5481e-04, -6.2214e-05,\n",
      "         -1.9934e-06, -1.0056e-05, -8.5139e-06, -8.5825e-06, -6.1500e-07,\n",
      "         -1.3186e-04, -6.5698e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 9.4122e-12,  1.2175e-11, -3.9102e-12,  6.6741e-11,  1.2594e-10,\n",
      "          9.5551e-11,  9.4063e-11,  1.1826e-11,  2.3699e-09,  6.1860e-10,\n",
      "          2.7925e-11,  1.2594e-10,  1.0496e-10,  1.0624e-10,  7.9159e-12,\n",
      "          1.1849e-09,  5.9245e-10],\n",
      "        [-3.7638e-03, -4.7976e-03,  1.2330e-03, -3.0090e-02, -7.7726e-02,\n",
      "         -5.8623e-02, -5.7019e-02, -5.9881e-03, -1.5267e+00, -3.8916e-01,\n",
      "         -4.4954e-03, -7.7411e-02, -6.2387e-02, -6.1816e-02, -4.7551e-03,\n",
      "         -9.7345e-01, -4.8259e-01]])}, 1: {'momentum_buffer': tensor([ 0.0000e+00,  2.7316e-05, -2.2969e-02, -1.7856e-05, -3.1588e-10,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -6.7710e-06,  0.0000e+00,\n",
      "         0.0000e+00, -1.2397e-06,  0.0000e+00,  3.4118e-04, -1.9792e-04,\n",
      "         0.0000e+00, -1.9901e-06,  0.0000e+00,  2.3831e-11, -1.8656e-02])}, 2: {'momentum_buffer': tensor([[ 0.0021,  0.0021, -0.0054, -0.0021,  0.0021, -0.0021,  0.0021,  0.0021,\n",
      "         -0.0021,  0.0021, -0.0021,  0.0021,  0.0021,  0.0021, -0.0021,  0.0021,\n",
      "         -0.0021, -0.0021,  0.0021, -0.0060],\n",
      "        [-0.0096, -0.0095,  0.0310,  0.0096, -0.0096,  0.0096, -0.0096, -0.0096,\n",
      "          0.0096, -0.0096,  0.0096, -0.0096, -0.0096, -0.0096,  0.0095, -0.0096,\n",
      "          0.0096,  0.0096, -0.0096,  0.0297],\n",
      "        [-0.0073, -0.0072,  0.0215,  0.0073, -0.0073,  0.0073, -0.0073, -0.0073,\n",
      "          0.0073, -0.0073,  0.0073, -0.0073, -0.0073, -0.0073,  0.0073, -0.0073,\n",
      "          0.0073,  0.0073, -0.0073,  0.0228],\n",
      "        [ 0.0033,  0.0033, -0.0078, -0.0033,  0.0033, -0.0033,  0.0033,  0.0033,\n",
      "         -0.0033,  0.0033, -0.0033,  0.0033,  0.0033,  0.0033, -0.0033,  0.0033,\n",
      "         -0.0033, -0.0033,  0.0033, -0.0090],\n",
      "        [ 0.0031,  0.0030, -0.0135, -0.0031,  0.0031, -0.0031,  0.0031,  0.0031,\n",
      "         -0.0031,  0.0031, -0.0031,  0.0031,  0.0031,  0.0031, -0.0031,  0.0031,\n",
      "         -0.0031, -0.0031,  0.0031, -0.0148],\n",
      "        [-0.0054, -0.0053,  0.0331,  0.0054, -0.0054,  0.0054, -0.0054, -0.0054,\n",
      "          0.0054, -0.0054,  0.0054, -0.0054, -0.0054, -0.0054,  0.0054, -0.0054,\n",
      "          0.0054,  0.0054, -0.0054,  0.0330],\n",
      "        [ 0.0067,  0.0066, -0.0216, -0.0067,  0.0067, -0.0067,  0.0067,  0.0067,\n",
      "         -0.0067,  0.0067, -0.0067,  0.0067,  0.0067,  0.0067, -0.0066,  0.0067,\n",
      "         -0.0067, -0.0067,  0.0067, -0.0212],\n",
      "        [ 0.0066,  0.0065, -0.0211, -0.0066,  0.0066, -0.0066,  0.0066,  0.0066,\n",
      "         -0.0066,  0.0066, -0.0066,  0.0066,  0.0066,  0.0066, -0.0065,  0.0066,\n",
      "         -0.0066, -0.0066,  0.0066, -0.0237],\n",
      "        [-0.0073, -0.0072,  0.0239,  0.0073, -0.0073,  0.0073, -0.0073, -0.0073,\n",
      "          0.0073, -0.0073,  0.0073, -0.0073, -0.0073, -0.0073,  0.0073, -0.0073,\n",
      "          0.0073,  0.0073, -0.0073,  0.0244],\n",
      "        [-0.0110, -0.0108,  0.0335,  0.0109, -0.0110,  0.0110, -0.0110, -0.0110,\n",
      "          0.0109, -0.0110,  0.0110, -0.0109, -0.0110, -0.0109,  0.0108, -0.0110,\n",
      "          0.0109,  0.0110, -0.0110,  0.0354]])}, 3: {'momentum_buffer': tensor([-0.0021,  0.0096,  0.0073, -0.0033, -0.0031,  0.0054, -0.0067, -0.0066,\n",
      "         0.0073,  0.0110])}, 4: {'momentum_buffer': tensor([[-0.0129,  0.0324,  0.0229, -0.0076, -0.0109,  0.0196, -0.0311, -0.0118,\n",
      "          0.0257,  0.0235],\n",
      "        [ 0.0129, -0.0324, -0.0229,  0.0076,  0.0109, -0.0196,  0.0311,  0.0118,\n",
      "         -0.0257, -0.0235]])}, 5: {'momentum_buffer': tensor([-0.0159,  0.0159])}}\n",
      "param_groups \t [{'lr': 0.001, 'momentum': 0.01, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "510244fed2737faa98f5c507705b781217d54f2f3afb1f6538ba23bbc323ff21"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('nassy-hasler-vBIYXc2u': pipenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}