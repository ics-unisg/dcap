{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from os import walk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>task</th>\n",
       "      <th>d_mean</th>\n",
       "      <th>d_median</th>\n",
       "      <th>d_std</th>\n",
       "      <th>e_min</th>\n",
       "      <th>e_max</th>\n",
       "      <th>e_mean</th>\n",
       "      <th>e_median</th>\n",
       "      <th>e_std</th>\n",
       "      <th>e_peak_count</th>\n",
       "      <th>e_peak_count_pm</th>\n",
       "      <th>b_min</th>\n",
       "      <th>b_max</th>\n",
       "      <th>b_mean</th>\n",
       "      <th>b_median</th>\n",
       "      <th>b_std</th>\n",
       "      <th>b_peak_count</th>\n",
       "      <th>b_peak_count_pm</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003</td>\n",
       "      <td>t2</td>\n",
       "      <td>0.220919</td>\n",
       "      <td>0.259452</td>\n",
       "      <td>-0.088826</td>\n",
       "      <td>2.173757</td>\n",
       "      <td>3.732305</td>\n",
       "      <td>2.909432</td>\n",
       "      <td>2.888242</td>\n",
       "      <td>0.304057</td>\n",
       "      <td>113</td>\n",
       "      <td>30.678733</td>\n",
       "      <td>1.184541</td>\n",
       "      <td>3.732305</td>\n",
       "      <td>3.130351</td>\n",
       "      <td>3.147694</td>\n",
       "      <td>0.215231</td>\n",
       "      <td>71</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001</td>\n",
       "      <td>t8</td>\n",
       "      <td>0.644607</td>\n",
       "      <td>0.904941</td>\n",
       "      <td>-0.224034</td>\n",
       "      <td>2.798857</td>\n",
       "      <td>5.320766</td>\n",
       "      <td>4.003479</td>\n",
       "      <td>3.777844</td>\n",
       "      <td>0.522086</td>\n",
       "      <td>147</td>\n",
       "      <td>25.789474</td>\n",
       "      <td>0.622869</td>\n",
       "      <td>5.320766</td>\n",
       "      <td>4.648087</td>\n",
       "      <td>4.682785</td>\n",
       "      <td>0.298052</td>\n",
       "      <td>33</td>\n",
       "      <td>16.363636</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003</td>\n",
       "      <td>t5</td>\n",
       "      <td>-0.015260</td>\n",
       "      <td>0.166744</td>\n",
       "      <td>0.346884</td>\n",
       "      <td>2.209762</td>\n",
       "      <td>3.790535</td>\n",
       "      <td>2.972422</td>\n",
       "      <td>2.975860</td>\n",
       "      <td>0.299366</td>\n",
       "      <td>93</td>\n",
       "      <td>27.623762</td>\n",
       "      <td>-0.104596</td>\n",
       "      <td>3.790535</td>\n",
       "      <td>2.957162</td>\n",
       "      <td>3.142604</td>\n",
       "      <td>0.646250</td>\n",
       "      <td>72</td>\n",
       "      <td>35.702479</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>005</td>\n",
       "      <td>t3</td>\n",
       "      <td>0.087266</td>\n",
       "      <td>0.028885</td>\n",
       "      <td>-0.076025</td>\n",
       "      <td>3.248507</td>\n",
       "      <td>4.961946</td>\n",
       "      <td>4.170758</td>\n",
       "      <td>4.238172</td>\n",
       "      <td>0.352659</td>\n",
       "      <td>79</td>\n",
       "      <td>32.689655</td>\n",
       "      <td>0.952023</td>\n",
       "      <td>4.961946</td>\n",
       "      <td>4.258024</td>\n",
       "      <td>4.267057</td>\n",
       "      <td>0.276634</td>\n",
       "      <td>67</td>\n",
       "      <td>33.223140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>008</td>\n",
       "      <td>t2</td>\n",
       "      <td>0.503004</td>\n",
       "      <td>0.458838</td>\n",
       "      <td>-0.240136</td>\n",
       "      <td>2.819035</td>\n",
       "      <td>5.837738</td>\n",
       "      <td>3.880701</td>\n",
       "      <td>3.895067</td>\n",
       "      <td>0.659222</td>\n",
       "      <td>135</td>\n",
       "      <td>37.327189</td>\n",
       "      <td>1.178414</td>\n",
       "      <td>5.837738</td>\n",
       "      <td>4.383705</td>\n",
       "      <td>4.353905</td>\n",
       "      <td>0.419087</td>\n",
       "      <td>117</td>\n",
       "      <td>58.016529</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>005</td>\n",
       "      <td>t5</td>\n",
       "      <td>0.628790</td>\n",
       "      <td>0.897065</td>\n",
       "      <td>-0.344902</td>\n",
       "      <td>2.325528</td>\n",
       "      <td>5.208260</td>\n",
       "      <td>3.783169</td>\n",
       "      <td>3.531106</td>\n",
       "      <td>0.641257</td>\n",
       "      <td>159</td>\n",
       "      <td>39.750000</td>\n",
       "      <td>0.965752</td>\n",
       "      <td>5.208260</td>\n",
       "      <td>4.411959</td>\n",
       "      <td>4.428171</td>\n",
       "      <td>0.296355</td>\n",
       "      <td>110</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002</td>\n",
       "      <td>t2</td>\n",
       "      <td>0.326944</td>\n",
       "      <td>0.419992</td>\n",
       "      <td>-0.056302</td>\n",
       "      <td>2.622484</td>\n",
       "      <td>4.641601</td>\n",
       "      <td>3.524013</td>\n",
       "      <td>3.450530</td>\n",
       "      <td>0.356463</td>\n",
       "      <td>143</td>\n",
       "      <td>30.211268</td>\n",
       "      <td>1.946925</td>\n",
       "      <td>4.641601</td>\n",
       "      <td>3.850957</td>\n",
       "      <td>3.870521</td>\n",
       "      <td>0.300161</td>\n",
       "      <td>64</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002</td>\n",
       "      <td>t4</td>\n",
       "      <td>0.273119</td>\n",
       "      <td>0.244724</td>\n",
       "      <td>-0.150913</td>\n",
       "      <td>2.567246</td>\n",
       "      <td>4.814949</td>\n",
       "      <td>3.697906</td>\n",
       "      <td>3.746131</td>\n",
       "      <td>0.478354</td>\n",
       "      <td>102</td>\n",
       "      <td>35.375723</td>\n",
       "      <td>1.032171</td>\n",
       "      <td>4.814949</td>\n",
       "      <td>3.971025</td>\n",
       "      <td>3.990854</td>\n",
       "      <td>0.327441</td>\n",
       "      <td>83</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002</td>\n",
       "      <td>t6</td>\n",
       "      <td>0.469124</td>\n",
       "      <td>0.572494</td>\n",
       "      <td>-0.068472</td>\n",
       "      <td>2.393223</td>\n",
       "      <td>4.824264</td>\n",
       "      <td>3.476828</td>\n",
       "      <td>3.365062</td>\n",
       "      <td>0.404711</td>\n",
       "      <td>126</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.214578</td>\n",
       "      <td>4.824264</td>\n",
       "      <td>3.945952</td>\n",
       "      <td>3.937556</td>\n",
       "      <td>0.336239</td>\n",
       "      <td>58</td>\n",
       "      <td>28.760331</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>005</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.103125</td>\n",
       "      <td>0.061807</td>\n",
       "      <td>-0.070540</td>\n",
       "      <td>3.184169</td>\n",
       "      <td>5.127730</td>\n",
       "      <td>4.199516</td>\n",
       "      <td>4.293928</td>\n",
       "      <td>0.403393</td>\n",
       "      <td>77</td>\n",
       "      <td>30.394737</td>\n",
       "      <td>1.045372</td>\n",
       "      <td>5.127730</td>\n",
       "      <td>4.302642</td>\n",
       "      <td>4.355734</td>\n",
       "      <td>0.332853</td>\n",
       "      <td>66</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject task    d_mean  d_median     d_std     e_min     e_max    e_mean  \\\n",
       "0      003   t2  0.220919  0.259452 -0.088826  2.173757  3.732305  2.909432   \n",
       "0      001   t8  0.644607  0.904941 -0.224034  2.798857  5.320766  4.003479   \n",
       "0      003   t5 -0.015260  0.166744  0.346884  2.209762  3.790535  2.972422   \n",
       "0      005   t3  0.087266  0.028885 -0.076025  3.248507  4.961946  4.170758   \n",
       "0      008   t2  0.503004  0.458838 -0.240136  2.819035  5.837738  3.880701   \n",
       "..     ...  ...       ...       ...       ...       ...       ...       ...   \n",
       "0      005   t5  0.628790  0.897065 -0.344902  2.325528  5.208260  3.783169   \n",
       "0      002   t2  0.326944  0.419992 -0.056302  2.622484  4.641601  3.524013   \n",
       "0      002   t4  0.273119  0.244724 -0.150913  2.567246  4.814949  3.697906   \n",
       "0      002   t6  0.469124  0.572494 -0.068472  2.393223  4.824264  3.476828   \n",
       "0      005   t1  0.103125  0.061807 -0.070540  3.184169  5.127730  4.199516   \n",
       "\n",
       "    e_median     e_std  e_peak_count  e_peak_count_pm     b_min     b_max  \\\n",
       "0   2.888242  0.304057           113        30.678733  1.184541  3.732305   \n",
       "0   3.777844  0.522086           147        25.789474  0.622869  5.320766   \n",
       "0   2.975860  0.299366            93        27.623762 -0.104596  3.790535   \n",
       "0   4.238172  0.352659            79        32.689655  0.952023  4.961946   \n",
       "0   3.895067  0.659222           135        37.327189  1.178414  5.837738   \n",
       "..       ...       ...           ...              ...       ...       ...   \n",
       "0   3.531106  0.641257           159        39.750000  0.965752  5.208260   \n",
       "0   3.450530  0.356463           143        30.211268  1.946925  4.641601   \n",
       "0   3.746131  0.478354           102        35.375723  1.032171  4.814949   \n",
       "0   3.365062  0.404711           126        22.500000  0.214578  4.824264   \n",
       "0   4.293928  0.403393            77        30.394737  1.045372  5.127730   \n",
       "\n",
       "      b_mean  b_median     b_std  b_peak_count  b_peak_count_pm  label  \n",
       "0   3.130351  3.147694  0.215231            71        35.500000      0  \n",
       "0   4.648087  4.682785  0.298052            33        16.363636      0  \n",
       "0   2.957162  3.142604  0.646250            72        35.702479      0  \n",
       "0   4.258024  4.267057  0.276634            67        33.223140      0  \n",
       "0   4.383705  4.353905  0.419087           117        58.016529      1  \n",
       "..       ...       ...       ...           ...              ...    ...  \n",
       "0   4.411959  4.428171  0.296355           110        55.000000      0  \n",
       "0   3.850957  3.870521  0.300161            64        32.000000      1  \n",
       "0   3.971025  3.990854  0.327441            83        41.500000      0  \n",
       "0   3.945952  3.937556  0.336239            58        28.760331      1  \n",
       "0   4.302642  4.355734  0.332853            66        33.000000      0  \n",
       "\n",
       "[64 rows x 20 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset is here: smb://nas-weber01.unisg.ch/data/Nassy/03_Online_Model/features\n",
    "_, _, file_names = next(walk('./dataset'))\n",
    "\n",
    "files = [(name.split('_')[0], name.split('_')[1].split('.')[0], name) for name in file_names]\n",
    "\n",
    "dataset = pd.DataFrame()\n",
    "\n",
    "for (subject_number, task, file_name) in files:\n",
    "    part = pd.read_csv(f'./dataset/{file_name}')\n",
    "    labels = pd.read_csv(f'./labels/{subject_number}.csv', sep=\";\").set_index('task')\n",
    "    rating = float(labels.loc[task]['r'])\n",
    "    part['label'] = int(rating > 4)\n",
    "    part['subject'] = subject_number\n",
    "\n",
    "    dataset = pd.concat([part, dataset])\n",
    "    \n",
    "dataset.tail(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILTER = (dataset['subject'] == '005')\n",
    "data_train = dataset[~TRAIN_FILTER].drop(['subject', 'task', 'label'], axis=1).to_numpy()\n",
    "data_test = dataset[TRAIN_FILTER].drop(['subject', 'task', 'label'], axis=1).to_numpy()\n",
    "\n",
    "targets_train = dataset[~TRAIN_FILTER]['label'].to_numpy()\n",
    "targets_test = dataset[TRAIN_FILTER]['label'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 17)\n",
      "(56,)\n",
      "(8, 17)\n",
      "(8,)\n"
     ]
    }
   ],
   "source": [
    "# test shapes\n",
    "print(data_train.shape)\n",
    "print(targets_train.shape)\n",
    "print(data_test.shape)\n",
    "print(targets_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## wrap data in dataset\n",
    "# cast to tensor\n",
    "data_train = torch.tensor(data_train).float()\n",
    "targets_train = torch.tensor(targets_train).long()#.unsqueeze(dim=-1)\n",
    "data_test = torch.tensor(data_test).float()\n",
    "targets_test = torch.tensor(targets_test).long()#.unsqueeze(dim=-1)\n",
    "# wrap in dataset class\n",
    "dataset_train = torch.utils.data.TensorDataset(data_train, targets_train)\n",
    "dataset_test = torch.utils.data.TensorDataset(data_test, targets_test)\n",
    "# create dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(dataset_train, batch_size=10,shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(dataset_test, batch_size=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create model\n",
    "class NN(torch.nn.Module):\n",
    "    def __init__(self, input_dimension,number_of_target_classes):\n",
    "        super().__init__()\n",
    "        # stack layers\n",
    "        self.module_list = torch.nn.ModuleList()\n",
    "        ## stacks contain of linear + nonlinear layers\n",
    "        self.module_list.append(torch.nn.Linear(input_dimension,20))\n",
    "        self.module_list.append(torch.nn.Tanh())\n",
    "        #\n",
    "        self.module_list.append(torch.nn.Linear(20,20))\n",
    "        self.module_list.append(torch.nn.Tanh())\n",
    "        #\n",
    "        self.module_list.append(torch.nn.Linear(20,10))\n",
    "        self.module_list.append(torch.nn.Tanh())\n",
    "        # map to output layer\n",
    "        self.module_list.append(torch.nn.Linear(10,number_of_target_classes))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        for module in self.module_list:\n",
    "            x = module(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2952, -0.3293],\n",
       "        [-0.2285, -0.3666],\n",
       "        [-0.3745, -0.2511],\n",
       "        [-0.3691, -0.2521],\n",
       "        [-0.2285, -0.3666],\n",
       "        [-0.2948, -0.3290],\n",
       "        [-0.3810, -0.2422],\n",
       "        [-0.3427, -0.2870],\n",
       "        [-0.2961, -0.3284],\n",
       "        [-0.3131, -0.3160]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instanciate model\n",
    "model = NN(17,2)\n",
    "#model.to(device)\n",
    "# test forward pass\n",
    "model(data_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def criterion and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "for epoch in range(2000):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, targets = data\n",
    "        inputs.to(device)\n",
    "        targets.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        # \n",
    "        targets = targets.squeeze()\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 0:    # print every 2000 mini-batches\n",
    "            #print('[%d, %5d] loss: %.3f' %\n",
    "            #      (epoch + 1, i + 1, running_loss / 20))\n",
    "            running_loss = 0.0\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './export/torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>task</th>\n",
       "      <th>d_mean</th>\n",
       "      <th>d_median</th>\n",
       "      <th>d_std</th>\n",
       "      <th>e_min</th>\n",
       "      <th>e_max</th>\n",
       "      <th>e_mean</th>\n",
       "      <th>e_median</th>\n",
       "      <th>e_std</th>\n",
       "      <th>e_peak_count</th>\n",
       "      <th>e_peak_count_pm</th>\n",
       "      <th>b_min</th>\n",
       "      <th>b_max</th>\n",
       "      <th>b_mean</th>\n",
       "      <th>b_median</th>\n",
       "      <th>b_std</th>\n",
       "      <th>b_peak_count</th>\n",
       "      <th>b_peak_count_pm</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003</td>\n",
       "      <td>t2</td>\n",
       "      <td>0.220919</td>\n",
       "      <td>0.259452</td>\n",
       "      <td>-0.088826</td>\n",
       "      <td>2.173757</td>\n",
       "      <td>3.732305</td>\n",
       "      <td>2.909432</td>\n",
       "      <td>2.888242</td>\n",
       "      <td>0.304057</td>\n",
       "      <td>113</td>\n",
       "      <td>30.678733</td>\n",
       "      <td>1.184541</td>\n",
       "      <td>3.732305</td>\n",
       "      <td>3.130351</td>\n",
       "      <td>3.147694</td>\n",
       "      <td>0.215231</td>\n",
       "      <td>71</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001</td>\n",
       "      <td>t8</td>\n",
       "      <td>0.644607</td>\n",
       "      <td>0.904941</td>\n",
       "      <td>-0.224034</td>\n",
       "      <td>2.798857</td>\n",
       "      <td>5.320766</td>\n",
       "      <td>4.003479</td>\n",
       "      <td>3.777844</td>\n",
       "      <td>0.522086</td>\n",
       "      <td>147</td>\n",
       "      <td>25.789474</td>\n",
       "      <td>0.622869</td>\n",
       "      <td>5.320766</td>\n",
       "      <td>4.648087</td>\n",
       "      <td>4.682785</td>\n",
       "      <td>0.298052</td>\n",
       "      <td>33</td>\n",
       "      <td>16.363636</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003</td>\n",
       "      <td>t5</td>\n",
       "      <td>-0.015260</td>\n",
       "      <td>0.166744</td>\n",
       "      <td>0.346884</td>\n",
       "      <td>2.209762</td>\n",
       "      <td>3.790535</td>\n",
       "      <td>2.972422</td>\n",
       "      <td>2.975860</td>\n",
       "      <td>0.299366</td>\n",
       "      <td>93</td>\n",
       "      <td>27.623762</td>\n",
       "      <td>-0.104596</td>\n",
       "      <td>3.790535</td>\n",
       "      <td>2.957162</td>\n",
       "      <td>3.142604</td>\n",
       "      <td>0.646250</td>\n",
       "      <td>72</td>\n",
       "      <td>35.702479</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>005</td>\n",
       "      <td>t3</td>\n",
       "      <td>0.087266</td>\n",
       "      <td>0.028885</td>\n",
       "      <td>-0.076025</td>\n",
       "      <td>3.248507</td>\n",
       "      <td>4.961946</td>\n",
       "      <td>4.170758</td>\n",
       "      <td>4.238172</td>\n",
       "      <td>0.352659</td>\n",
       "      <td>79</td>\n",
       "      <td>32.689655</td>\n",
       "      <td>0.952023</td>\n",
       "      <td>4.961946</td>\n",
       "      <td>4.258024</td>\n",
       "      <td>4.267057</td>\n",
       "      <td>0.276634</td>\n",
       "      <td>67</td>\n",
       "      <td>33.223140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>008</td>\n",
       "      <td>t2</td>\n",
       "      <td>0.503004</td>\n",
       "      <td>0.458838</td>\n",
       "      <td>-0.240136</td>\n",
       "      <td>2.819035</td>\n",
       "      <td>5.837738</td>\n",
       "      <td>3.880701</td>\n",
       "      <td>3.895067</td>\n",
       "      <td>0.659222</td>\n",
       "      <td>135</td>\n",
       "      <td>37.327189</td>\n",
       "      <td>1.178414</td>\n",
       "      <td>5.837738</td>\n",
       "      <td>4.383705</td>\n",
       "      <td>4.353905</td>\n",
       "      <td>0.419087</td>\n",
       "      <td>117</td>\n",
       "      <td>58.016529</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>005</td>\n",
       "      <td>t5</td>\n",
       "      <td>0.628790</td>\n",
       "      <td>0.897065</td>\n",
       "      <td>-0.344902</td>\n",
       "      <td>2.325528</td>\n",
       "      <td>5.208260</td>\n",
       "      <td>3.783169</td>\n",
       "      <td>3.531106</td>\n",
       "      <td>0.641257</td>\n",
       "      <td>159</td>\n",
       "      <td>39.750000</td>\n",
       "      <td>0.965752</td>\n",
       "      <td>5.208260</td>\n",
       "      <td>4.411959</td>\n",
       "      <td>4.428171</td>\n",
       "      <td>0.296355</td>\n",
       "      <td>110</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002</td>\n",
       "      <td>t2</td>\n",
       "      <td>0.326944</td>\n",
       "      <td>0.419992</td>\n",
       "      <td>-0.056302</td>\n",
       "      <td>2.622484</td>\n",
       "      <td>4.641601</td>\n",
       "      <td>3.524013</td>\n",
       "      <td>3.450530</td>\n",
       "      <td>0.356463</td>\n",
       "      <td>143</td>\n",
       "      <td>30.211268</td>\n",
       "      <td>1.946925</td>\n",
       "      <td>4.641601</td>\n",
       "      <td>3.850957</td>\n",
       "      <td>3.870521</td>\n",
       "      <td>0.300161</td>\n",
       "      <td>64</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002</td>\n",
       "      <td>t4</td>\n",
       "      <td>0.273119</td>\n",
       "      <td>0.244724</td>\n",
       "      <td>-0.150913</td>\n",
       "      <td>2.567246</td>\n",
       "      <td>4.814949</td>\n",
       "      <td>3.697906</td>\n",
       "      <td>3.746131</td>\n",
       "      <td>0.478354</td>\n",
       "      <td>102</td>\n",
       "      <td>35.375723</td>\n",
       "      <td>1.032171</td>\n",
       "      <td>4.814949</td>\n",
       "      <td>3.971025</td>\n",
       "      <td>3.990854</td>\n",
       "      <td>0.327441</td>\n",
       "      <td>83</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002</td>\n",
       "      <td>t6</td>\n",
       "      <td>0.469124</td>\n",
       "      <td>0.572494</td>\n",
       "      <td>-0.068472</td>\n",
       "      <td>2.393223</td>\n",
       "      <td>4.824264</td>\n",
       "      <td>3.476828</td>\n",
       "      <td>3.365062</td>\n",
       "      <td>0.404711</td>\n",
       "      <td>126</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.214578</td>\n",
       "      <td>4.824264</td>\n",
       "      <td>3.945952</td>\n",
       "      <td>3.937556</td>\n",
       "      <td>0.336239</td>\n",
       "      <td>58</td>\n",
       "      <td>28.760331</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>005</td>\n",
       "      <td>t1</td>\n",
       "      <td>0.103125</td>\n",
       "      <td>0.061807</td>\n",
       "      <td>-0.070540</td>\n",
       "      <td>3.184169</td>\n",
       "      <td>5.127730</td>\n",
       "      <td>4.199516</td>\n",
       "      <td>4.293928</td>\n",
       "      <td>0.403393</td>\n",
       "      <td>77</td>\n",
       "      <td>30.394737</td>\n",
       "      <td>1.045372</td>\n",
       "      <td>5.127730</td>\n",
       "      <td>4.302642</td>\n",
       "      <td>4.355734</td>\n",
       "      <td>0.332853</td>\n",
       "      <td>66</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject task    d_mean  d_median     d_std     e_min     e_max    e_mean  \\\n",
       "0      003   t2  0.220919  0.259452 -0.088826  2.173757  3.732305  2.909432   \n",
       "0      001   t8  0.644607  0.904941 -0.224034  2.798857  5.320766  4.003479   \n",
       "0      003   t5 -0.015260  0.166744  0.346884  2.209762  3.790535  2.972422   \n",
       "0      005   t3  0.087266  0.028885 -0.076025  3.248507  4.961946  4.170758   \n",
       "0      008   t2  0.503004  0.458838 -0.240136  2.819035  5.837738  3.880701   \n",
       "..     ...  ...       ...       ...       ...       ...       ...       ...   \n",
       "0      005   t5  0.628790  0.897065 -0.344902  2.325528  5.208260  3.783169   \n",
       "0      002   t2  0.326944  0.419992 -0.056302  2.622484  4.641601  3.524013   \n",
       "0      002   t4  0.273119  0.244724 -0.150913  2.567246  4.814949  3.697906   \n",
       "0      002   t6  0.469124  0.572494 -0.068472  2.393223  4.824264  3.476828   \n",
       "0      005   t1  0.103125  0.061807 -0.070540  3.184169  5.127730  4.199516   \n",
       "\n",
       "    e_median     e_std  e_peak_count  e_peak_count_pm     b_min     b_max  \\\n",
       "0   2.888242  0.304057           113        30.678733  1.184541  3.732305   \n",
       "0   3.777844  0.522086           147        25.789474  0.622869  5.320766   \n",
       "0   2.975860  0.299366            93        27.623762 -0.104596  3.790535   \n",
       "0   4.238172  0.352659            79        32.689655  0.952023  4.961946   \n",
       "0   3.895067  0.659222           135        37.327189  1.178414  5.837738   \n",
       "..       ...       ...           ...              ...       ...       ...   \n",
       "0   3.531106  0.641257           159        39.750000  0.965752  5.208260   \n",
       "0   3.450530  0.356463           143        30.211268  1.946925  4.641601   \n",
       "0   3.746131  0.478354           102        35.375723  1.032171  4.814949   \n",
       "0   3.365062  0.404711           126        22.500000  0.214578  4.824264   \n",
       "0   4.293928  0.403393            77        30.394737  1.045372  5.127730   \n",
       "\n",
       "      b_mean  b_median     b_std  b_peak_count  b_peak_count_pm  label  \n",
       "0   3.130351  3.147694  0.215231            71        35.500000      0  \n",
       "0   4.648087  4.682785  0.298052            33        16.363636      0  \n",
       "0   2.957162  3.142604  0.646250            72        35.702479      0  \n",
       "0   4.258024  4.267057  0.276634            67        33.223140      0  \n",
       "0   4.383705  4.353905  0.419087           117        58.016529      1  \n",
       "..       ...       ...       ...           ...              ...    ...  \n",
       "0   4.411959  4.428171  0.296355           110        55.000000      0  \n",
       "0   3.850957  3.870521  0.300161            64        32.000000      1  \n",
       "0   3.971025  3.990854  0.327441            83        41.500000      0  \n",
       "0   3.945952  3.937556  0.336239            58        28.760331      1  \n",
       "0   4.302642  4.355734  0.332853            66        33.000000      0  \n",
       "\n",
       "[64 rows x 20 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0580, -0.5601]) tensor(0) 0 001 t8\n",
      "tensor([ 0.7590, -1.1928]) tensor(0) 0 003 t5\n",
      "tensor([ 0.7785, -1.2118]) tensor(0) 0 005 t3\n",
      "tensor([-0.0792, -0.3710]) tensor(0) 1 008 t2\n",
      "tensor([ 0.0580, -0.5601]) tensor(0) 0 001 t5\n",
      "tensor([-0.8895,  0.3736]) tensor(1) 1 008 t7\n",
      "tensor([ 0.6433, -1.0805]) tensor(0) 1 002 t5\n",
      "tensor([ 0.7693, -1.2031]) tensor(0) 0 005 t7\n",
      "tensor([ 0.7785, -1.2117]) tensor(0) 0 003 t3\n",
      "tensor([-0.9050,  0.3886]) tensor(1) 1 002 t8\n",
      "tensor([ 0.7799, -1.2131]) tensor(0) 0 008 t1\n",
      "tensor([-0.1157, -0.3939]) tensor(0) 0 003 t6\n",
      "tensor([-0.2033, -0.3095]) tensor(0) 0 004 t8\n",
      "tensor([ 0.8738, -1.3057]) tensor(0) 0 006 t7\n",
      "tensor([ 0.0580, -0.5601]) tensor(0) 1 001 t7\n",
      "tensor([ 0.7847, -1.2179]) tensor(0) 0 007 t1\n",
      "tensor([ 0.8332, -1.2657]) tensor(0) 0 005 t4\n",
      "tensor([ 0.8779, -1.3094]) tensor(0) 0 006 t3\n",
      "tensor([ 0.7783, -1.2116]) tensor(0) 0 004 t3\n",
      "tensor([ 0.7786, -1.2118]) tensor(0) 0 008 t4\n",
      "tensor([ 0.0799, -0.5539]) tensor(0) 0 006 t8\n",
      "tensor([ 0.0579, -0.5600]) tensor(0) 0 001 t1\n",
      "tensor([ 0.0580, -0.5601]) tensor(0) 1 007 t6\n",
      "tensor([ 0.9604, -1.3898]) tensor(0) 0 001 t3\n",
      "tensor([ 0.7296, -1.1644]) tensor(0) 0 006 t2\n",
      "tensor([ 0.7815, -1.2148]) tensor(0) 0 006 t5\n",
      "tensor([ 0.7858, -1.2189]) tensor(0) 1 007 t4\n",
      "tensor([ 0.7792, -1.2124]) tensor(0) 0 002 t3\n",
      "tensor([ 0.7572, -1.1912]) tensor(0) 0 007 t3\n",
      "tensor([-0.8479,  0.3335]) tensor(1) 1 008 t6\n",
      "tensor([ 0.4740, -0.9342]) tensor(0) 0 004 t1\n",
      "tensor([ 0.6549, -1.0917]) tensor(0) 0 004 t4\n",
      "tensor([ 0.0540, -0.5563]) tensor(0) 0 004 t7\n",
      "tensor([-0.8347,  0.3198]) tensor(1) 1 005 t8\n",
      "tensor([ 0.7792, -1.2124]) tensor(0) 0 008 t3\n",
      "tensor([-0.0672, -0.3840]) tensor(0) 0 003 t7\n",
      "tensor([ 0.7732, -1.2068]) tensor(0) 0 004 t5\n",
      "tensor([ 0.7535, -1.1875]) tensor(0) 0 003 t4\n",
      "tensor([ 1.2174, -1.6423]) tensor(0) 0 006 t6\n",
      "tensor([ 0.7468, -1.1809]) tensor(0) 0 002 t7\n",
      "tensor([ 0.0580, -0.5601]) tensor(0) 0 004 t2\n",
      "tensor([ 0.0567, -0.5589]) tensor(0) 1 007 t8\n",
      "tensor([ 0.3213, -0.7815]) tensor(0) 0 005 t2\n",
      "tensor([ 0.4390, -0.8813]) tensor(0) 0 008 t5\n",
      "tensor([ 0.7826, -1.2158]) tensor(0) 0 003 t1\n",
      "tensor([-0.9111,  0.3945]) tensor(1) 1 008 t8\n",
      "tensor([ 0.7832, -1.2164]) tensor(0) 1 007 t5\n",
      "tensor([-0.8416,  0.3275]) tensor(1) 1 005 t6\n",
      "tensor([ 1.1051, -1.5388]) tensor(0) 0 007 t7\n",
      "tensor([ 0.0580, -0.5601]) tensor(0) 1 001 t6\n",
      "tensor([ 0.7787, -1.2120]) tensor(0) 0 002 t1\n",
      "tensor([ 0.0580, -0.5601]) tensor(0) 0 003 t8\n",
      "tensor([ 0.0580, -0.5601]) tensor(0) 0 001 t2\n",
      "tensor([ 0.6953, -1.1309]) tensor(0) 0 006 t4\n",
      "tensor([ 0.0580, -0.5601]) tensor(0) 0 004 t6\n",
      "tensor([-0.2857, -0.2298]) tensor(1) 0 007 t2\n",
      "tensor([ 1.3540, -1.7750]) tensor(0) 0 001 t4\n",
      "tensor([ 0.6927, -1.1313]) tensor(0) 0 006 t1\n",
      "tensor([ 0.0346, -0.5100]) tensor(0) 0 005 t5\n",
      "tensor([ 0.0201, -0.5239]) tensor(0) 1 002 t2\n",
      "tensor([ 0.7701, -1.2036]) tensor(0) 0 002 t4\n",
      "tensor([-0.7437,  0.2226]) tensor(1) 1 002 t6\n",
      "tensor([ 0.7621, -1.1958]) tensor(0) 0 005 t1\n",
      "53 63 0.8412698412698413\n"
     ]
    }
   ],
   "source": [
    "\n",
    "right = 0\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    device = torch.device('cuda')\n",
    "    model2 = NN(17,2)\n",
    "    model2.load_state_dict(torch.load('./export/torch', map_location=device))\n",
    "    model2.eval()\n",
    "\n",
    "    for index in list(range(1, 64)):\n",
    "        data_to_predict = dataset.drop(['subject', 'task', 'label'], axis=1).to_numpy()[index]\n",
    "\n",
    "        prediction = model2(torch.from_numpy(data_to_predict).float())\n",
    "        predicted_class = np.argmax(prediction)\n",
    "        print(prediction, predicted_class, dataset.iloc[index]['label'], dataset.iloc[index]['subject'], dataset.iloc[index]['task'])\n",
    "        right += 1 if predicted_class == dataset.iloc[index]['label'] else 0\n",
    "        count += 1\n",
    "\n",
    "print(right, count, right/count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "module_list.0.weight \t torch.Size([20, 17])\n",
      "module_list.0.bias \t torch.Size([20])\n",
      "module_list.2.weight \t torch.Size([20, 20])\n",
      "module_list.2.bias \t torch.Size([20])\n",
      "module_list.4.weight \t torch.Size([10, 20])\n",
      "module_list.4.bias \t torch.Size([10])\n",
      "module_list.6.weight \t torch.Size([2, 10])\n",
      "module_list.6.bias \t torch.Size([2])\n",
      "Optimizer's state_dict:\n",
      "state \t {0: {'momentum_buffer': tensor([[-2.2441e-14, -2.4744e-14,  1.0638e-14, -2.4132e-13, -4.0518e-13,\n",
      "         -3.1186e-13, -3.0966e-13, -3.0166e-14, -4.2241e-12, -1.1601e-12,\n",
      "         -1.1015e-13, -4.0846e-13, -3.3430e-13, -3.3441e-13, -1.9528e-14,\n",
      "         -2.6134e-12, -1.3012e-12],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 1.7585e-05,  2.2746e-05, -4.6916e-06,  1.1769e-04,  2.2328e-04,\n",
      "          1.6582e-04,  1.6171e-04,  2.0977e-05,  5.9446e-03,  1.5257e-03,\n",
      "         -5.6621e-06,  2.2328e-04,  1.8341e-04,  1.8445e-04,  1.6285e-05,\n",
      "          5.0520e-03,  2.5051e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-9.8355e-13, -6.4627e-13,  5.6650e-13, -1.4654e-11, -2.5114e-11,\n",
      "         -1.9246e-11, -1.9620e-11, -1.9592e-12, -2.6643e-10, -9.0993e-11,\n",
      "         -6.8661e-12, -2.5119e-11, -2.0229e-11, -2.0266e-11, -1.3927e-12,\n",
      "         -2.0152e-10, -1.0074e-10],\n",
      "        [ 1.4015e-14,  1.7264e-14, -6.0296e-15,  1.3780e-13,  2.3066e-13,\n",
      "          1.7696e-13,  1.7394e-13,  1.6859e-14,  2.1879e-12,  5.4289e-13,\n",
      "          5.4391e-14,  2.3066e-13,  1.9098e-13,  1.9121e-13,  1.0829e-14,\n",
      "          1.1266e-12,  5.6309e-13],\n",
      "        [ 4.9345e-15,  6.0787e-15, -2.1216e-15,  4.8621e-14,  8.1354e-14,\n",
      "          6.2426e-14,  6.1362e-14,  5.9428e-15,  7.7219e-13,  1.9173e-13,\n",
      "          1.9164e-14,  8.1354e-14,  6.7360e-14,  6.7441e-14,  3.8212e-15,\n",
      "          3.9774e-13,  1.9879e-13],\n",
      "        [ 6.6245e-03,  9.8538e-03, -1.5965e-03,  6.2604e-02,  1.1567e-01,\n",
      "          8.3732e-02,  8.0245e-02,  1.0398e-02,  1.6951e+00,  4.8554e-01,\n",
      "          6.7244e-02,  1.1568e-01,  9.0357e-02,  9.0099e-02,  8.8017e-03,\n",
      "          1.1827e+00,  5.8640e-01],\n",
      "        [ 1.9125e-12,  2.3499e-12, -8.1283e-13,  1.8607e-11,  3.1294e-11,\n",
      "          2.3997e-11,  2.3591e-11,  2.2911e-12,  3.0894e-10,  7.6272e-11,\n",
      "          7.2665e-12,  3.1300e-11,  2.5909e-11,  2.5941e-11,  1.4782e-12,\n",
      "          1.5959e-10,  7.9694e-11],\n",
      "        [-3.9552e-06, -4.2118e-06,  1.4375e-06, -2.4435e-05, -4.6674e-05,\n",
      "         -3.4787e-05, -3.4834e-05, -4.5310e-06, -1.2358e-03, -3.1843e-04,\n",
      "          9.1857e-06, -4.6673e-05, -3.8742e-05, -3.9046e-05, -3.0936e-06,\n",
      "         -1.0827e-03, -5.3686e-04],\n",
      "        [-1.0174e-07, -7.5481e-08,  5.6210e-08, -8.0103e-07, -1.5044e-06,\n",
      "         -1.1044e-06, -1.1338e-06, -1.4354e-07, -1.7612e-05, -5.3771e-06,\n",
      "         -3.4355e-07, -1.5043e-06, -1.2062e-06, -1.2092e-06, -8.7327e-08,\n",
      "         -1.3522e-05, -6.7072e-06],\n",
      "        [-1.0471e-02, -1.5512e-02,  3.6898e-03, -5.1013e-02, -9.7321e-02,\n",
      "         -6.5509e-02, -5.9631e-02, -1.0329e-02, -2.0023e+00, -4.1685e-01,\n",
      "         -3.5078e-02, -9.7469e-02, -7.5980e-02, -7.5143e-02, -6.6397e-03,\n",
      "         -1.0624e+00, -5.2671e-01],\n",
      "        [-2.9862e-05, -2.4090e-05,  1.6003e-05, -2.3553e-04, -4.4192e-04,\n",
      "         -3.2372e-04, -3.3036e-04, -4.2218e-05, -5.1602e-03, -1.5738e-03,\n",
      "         -1.0889e-04, -4.4191e-04, -3.5359e-04, -3.5445e-04, -2.6214e-05,\n",
      "         -3.8498e-03, -1.9095e-03],\n",
      "        [ 5.0195e-08,  3.7645e-08, -2.7729e-08,  3.9914e-07,  7.4634e-07,\n",
      "          5.4750e-07,  5.6137e-07,  7.1127e-08,  8.4749e-06,  2.5990e-06,\n",
      "          1.8518e-07,  7.4633e-07,  5.9770e-07,  5.9902e-07,  4.3399e-08,\n",
      "          6.4117e-06,  3.1797e-06],\n",
      "        [ 1.3473e-09,  1.0488e-09, -7.2450e-10,  1.0691e-08,  2.0001e-08,\n",
      "          1.4668e-08,  1.5002e-08,  1.9037e-09,  2.3409e-07,  7.1143e-08,\n",
      "          5.0524e-09,  2.0001e-08,  1.6015e-08,  1.6050e-08,  1.1792e-09,\n",
      "          1.7773e-07,  8.8143e-08],\n",
      "        [ 1.2875e-15,  1.5857e-15, -5.5871e-16,  1.2312e-14,  2.0711e-14,\n",
      "          1.5856e-14,  1.5580e-14,  1.5256e-15,  1.9475e-13,  4.7891e-14,\n",
      "          4.9507e-15,  2.0711e-14,  1.7143e-14,  1.7165e-14,  9.6685e-16,\n",
      "          9.9874e-14,  4.9937e-14],\n",
      "        [ 3.0909e-02,  3.7883e-02, -4.5416e-03,  1.5508e-01,  3.1116e-01,\n",
      "          2.2406e-01,  2.1640e-01,  2.6102e-02,  7.9805e+00,  1.4243e+00,\n",
      "          1.5305e-02,  3.1135e-01,  2.5497e-01,  2.5429e-01,  2.1561e-02,\n",
      "          3.6866e+00,  1.8281e+00],\n",
      "        [-3.0115e-11, -2.3145e-11,  1.6277e-11, -2.4768e-10, -4.6081e-10,\n",
      "         -3.3889e-10, -3.4667e-10, -4.3385e-11, -5.3662e-09, -1.6471e-09,\n",
      "         -1.1720e-10, -4.6082e-10, -3.6900e-10, -3.6982e-10, -2.7108e-11,\n",
      "         -4.0845e-09, -2.0267e-09]])}, 1: {'momentum_buffer': tensor([-9.8044e-14,  0.0000e+00,  5.7596e-05,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -5.1915e-12,  5.5654e-14,  1.9631e-14,  2.0953e-02,\n",
      "         7.5523e-12, -1.2597e-05, -3.0665e-07, -1.7171e-02, -8.8463e-05,\n",
      "         1.5070e-07,  4.0413e-09,  4.9937e-15,  6.4099e-02, -9.3070e-11])}, 2: {'momentum_buffer': tensor([[ 3.2154e-02, -3.2154e-02,  3.2244e-02, -3.2154e-02,  3.2154e-02,\n",
      "         -3.2154e-02, -3.2154e-02, -3.2154e-02,  3.2154e-02, -6.6142e-02,\n",
      "         -3.2154e-02, -3.2162e-02,  3.2159e-02, -4.4244e-03,  3.2176e-02,\n",
      "          3.2154e-02,  3.2154e-02, -3.2154e-02,  3.0819e-02,  3.2154e-02],\n",
      "        [-5.3466e-03,  5.3466e-03, -5.3661e-03,  5.3466e-03, -5.3466e-03,\n",
      "          5.3466e-03,  5.3466e-03,  5.3466e-03, -5.3466e-03,  1.2846e-02,\n",
      "          5.3466e-03,  5.3484e-03, -5.3476e-03,  6.5455e-04, -5.3509e-03,\n",
      "         -5.3466e-03, -5.3466e-03,  5.3466e-03, -7.3346e-03, -5.3466e-03],\n",
      "        [-4.5377e-02,  4.5377e-02, -4.5472e-02,  4.5377e-02, -4.5377e-02,\n",
      "          4.5377e-02,  4.5377e-02,  4.5377e-02, -4.5377e-02,  8.0542e-02,\n",
      "          4.5377e-02,  4.5385e-02, -4.5383e-02,  3.2856e-03, -4.5405e-02,\n",
      "         -4.5377e-02, -4.5377e-02,  4.5377e-02, -4.3230e-02, -4.5377e-02],\n",
      "        [-5.3520e-02,  5.3520e-02, -5.3645e-02,  5.3520e-02, -5.3520e-02,\n",
      "          5.3520e-02,  5.3520e-02,  5.3520e-02, -5.3520e-02,  9.9582e-02,\n",
      "          5.3520e-02,  5.3531e-02, -5.3528e-02,  2.8596e-03, -5.3555e-02,\n",
      "         -5.3520e-02, -5.3520e-02,  5.3520e-02, -5.2245e-02, -5.3520e-02],\n",
      "        [-3.0622e-02,  3.0622e-02, -3.0678e-02,  3.0622e-02, -3.0622e-02,\n",
      "          3.0622e-02,  3.0622e-02,  3.0622e-02, -3.0622e-02,  5.0919e-02,\n",
      "          3.0622e-02,  3.0627e-02, -3.0626e-02,  2.5978e-03, -3.0639e-02,\n",
      "         -3.0622e-02, -3.0622e-02,  3.0622e-02, -2.5685e-02, -3.0622e-02],\n",
      "        [-2.2846e-02,  2.2846e-02, -2.2892e-02,  2.2846e-02, -2.2846e-02,\n",
      "          2.2846e-02,  2.2846e-02,  2.2846e-02, -2.2846e-02,  4.0182e-02,\n",
      "          2.2846e-02,  2.2850e-02, -2.2849e-02,  4.2717e-03, -2.2858e-02,\n",
      "         -2.2846e-02, -2.2846e-02,  2.2846e-02, -1.9103e-02, -2.2846e-02],\n",
      "        [ 1.1057e-02, -1.1057e-02,  1.1092e-02, -1.1057e-02,  1.1057e-02,\n",
      "         -1.1057e-02, -1.1057e-02, -1.1057e-02,  1.1057e-02, -2.4286e-02,\n",
      "         -1.1057e-02, -1.1060e-02,  1.1059e-02, -1.2435e-03,  1.1065e-02,\n",
      "          1.1057e-02,  1.1057e-02, -1.1057e-02,  1.1617e-02,  1.1057e-02],\n",
      "        [-9.0354e-03,  9.0354e-03, -9.0575e-03,  9.0354e-03, -9.0354e-03,\n",
      "          9.0354e-03,  9.0354e-03,  9.0354e-03, -9.0354e-03,  1.7225e-02,\n",
      "          9.0354e-03,  9.0374e-03, -9.0368e-03, -1.0939e-05, -9.0415e-03,\n",
      "         -9.0355e-03, -9.0354e-03,  9.0354e-03, -9.3838e-03, -9.0354e-03],\n",
      "        [-9.3546e-03,  9.3546e-03, -9.3812e-03,  9.3546e-03, -9.3546e-03,\n",
      "          9.3546e-03,  9.3546e-03,  9.3546e-03, -9.3546e-03,  1.9343e-02,\n",
      "          9.3546e-03,  9.3570e-03, -9.3561e-03, -2.2541e-05, -9.3616e-03,\n",
      "         -9.3546e-03, -9.3546e-03,  9.3546e-03, -9.7658e-03, -9.3546e-03],\n",
      "        [ 2.4890e-02, -2.4890e-02,  2.4935e-02, -2.4890e-02,  2.4890e-02,\n",
      "         -2.4890e-02, -2.4890e-02, -2.4890e-02,  2.4890e-02, -4.0836e-02,\n",
      "         -2.4890e-02, -2.4894e-02,  2.4893e-02, -1.5111e-04,  2.4905e-02,\n",
      "          2.4890e-02,  2.4890e-02, -2.4890e-02,  2.3050e-02,  2.4890e-02],\n",
      "        [-1.9729e-02,  1.9729e-02, -1.9766e-02,  1.9729e-02, -1.9729e-02,\n",
      "          1.9729e-02,  1.9729e-02,  1.9729e-02, -1.9729e-02,  3.3004e-02,\n",
      "          1.9729e-02,  1.9732e-02, -1.9732e-02,  2.9948e-04, -1.9741e-02,\n",
      "         -1.9729e-02, -1.9729e-02,  1.9729e-02, -1.8494e-02, -1.9729e-02],\n",
      "        [-5.9339e-02,  5.9339e-02, -5.9453e-02,  5.9339e-02, -5.9339e-02,\n",
      "          5.9339e-02,  5.9339e-02,  5.9339e-02, -5.9339e-02,  1.0057e-01,\n",
      "          5.9339e-02,  5.9349e-02, -5.9347e-02,  1.5672e-04, -5.9375e-02,\n",
      "         -5.9339e-02, -5.9339e-02,  5.9339e-02, -5.7304e-02, -5.9339e-02],\n",
      "        [-5.4730e-02,  5.4730e-02, -5.4851e-02,  5.4730e-02, -5.4730e-02,\n",
      "          5.4730e-02,  5.4730e-02,  5.4730e-02, -5.4730e-02,  9.9647e-02,\n",
      "          5.4730e-02,  5.4741e-02, -5.4738e-02,  6.3091e-03, -5.4763e-02,\n",
      "         -5.4730e-02, -5.4730e-02,  5.4730e-02, -5.3049e-02, -5.4730e-02],\n",
      "        [-5.0628e-02,  5.0628e-02, -5.0738e-02,  5.0628e-02, -5.0628e-02,\n",
      "          5.0628e-02,  5.0628e-02,  5.0628e-02, -5.0628e-02,  9.1804e-02,\n",
      "          5.0628e-02,  5.0638e-02, -5.0634e-02,  9.2885e-03, -5.0657e-02,\n",
      "         -5.0628e-02, -5.0628e-02,  5.0628e-02, -4.6657e-02, -5.0628e-02],\n",
      "        [-2.2442e-02,  2.2442e-02, -2.2488e-02,  2.2442e-02, -2.2442e-02,\n",
      "          2.2442e-02,  2.2442e-02,  2.2442e-02, -2.2442e-02,  3.9372e-02,\n",
      "          2.2442e-02,  2.2446e-02, -2.2445e-02,  3.6452e-03, -2.2455e-02,\n",
      "         -2.2442e-02, -2.2442e-02,  2.2442e-02, -2.2152e-02, -2.2442e-02],\n",
      "        [-4.0355e-02,  4.0355e-02, -4.0396e-02,  4.0355e-02, -4.0355e-02,\n",
      "          4.0355e-02,  4.0355e-02,  4.0355e-02, -4.0355e-02,  5.4223e-02,\n",
      "          4.0355e-02,  4.0358e-02, -4.0359e-02,  6.3016e-03, -4.0372e-02,\n",
      "         -4.0355e-02, -4.0355e-02,  4.0355e-02, -3.4581e-02, -4.0355e-02],\n",
      "        [-5.1827e-03,  5.1827e-03, -5.2019e-03,  5.1827e-03, -5.1827e-03,\n",
      "          5.1827e-03,  5.1827e-03,  5.1827e-03, -5.1827e-03,  1.2571e-02,\n",
      "          5.1827e-03,  5.1845e-03, -5.1836e-03,  1.6886e-04, -5.1870e-03,\n",
      "         -5.1827e-03, -5.1827e-03,  5.1827e-03, -5.5621e-03, -5.1827e-03],\n",
      "        [ 8.3946e-02, -8.3946e-02,  8.4131e-02, -8.3946e-02,  8.3946e-02,\n",
      "         -8.3946e-02, -8.3946e-02, -8.3946e-02,  8.3946e-02, -1.5238e-01,\n",
      "         -8.3946e-02, -8.3963e-02,  8.3958e-02, -6.7852e-03,  8.3998e-02,\n",
      "          8.3946e-02,  8.3946e-02, -8.3946e-02,  8.0569e-02,  8.3946e-02],\n",
      "        [ 4.4213e-02, -4.4213e-02,  4.4314e-02, -4.4213e-02,  4.4213e-02,\n",
      "         -4.4213e-02, -4.4213e-02, -4.4213e-02,  4.4213e-02, -8.1932e-02,\n",
      "         -4.4213e-02, -4.4222e-02,  4.4219e-02, -5.2443e-03,  4.4240e-02,\n",
      "          4.4213e-02,  4.4213e-02, -4.4213e-02,  4.2893e-02,  4.4213e-02],\n",
      "        [ 1.2447e-01, -1.2447e-01,  1.2477e-01, -1.2447e-01,  1.2447e-01,\n",
      "         -1.2447e-01, -1.2447e-01, -1.2447e-01,  1.2447e-01, -2.3891e-01,\n",
      "         -1.2447e-01, -1.2449e-01,  1.2448e-01, -1.1953e-02,  1.2454e-01,\n",
      "          1.2447e-01,  1.2447e-01, -1.2447e-01,  1.2047e-01,  1.2447e-01]])}, 3: {'momentum_buffer': tensor([-0.0322,  0.0053,  0.0454,  0.0535,  0.0306,  0.0228, -0.0111,  0.0090,\n",
      "         0.0094, -0.0249,  0.0197,  0.0593,  0.0547,  0.0506,  0.0224,  0.0404,\n",
      "         0.0052, -0.0839, -0.0442, -0.1245])}, 4: {'momentum_buffer': tensor([[ 4.0568e-02, -3.2375e-02,  3.0304e-02, -4.4967e-03, -1.0269e-02,\n",
      "         -4.4279e-02,  3.5553e-02,  1.2013e-02,  2.6300e-02,  5.6164e-03,\n",
      "          1.8432e-02, -2.5390e-03, -2.3214e-03, -1.4675e-02, -2.2209e-03,\n",
      "         -2.9781e-02,  2.6449e-02, -4.0225e-03,  1.3426e-02, -6.8992e-04],\n",
      "        [ 3.5638e-02, -2.9019e-02,  2.6729e-02, -4.3577e-03, -9.0370e-03,\n",
      "         -3.9705e-02,  3.1596e-02,  1.0642e-02,  2.3110e-02,  4.6860e-03,\n",
      "          1.6072e-02, -2.2585e-03, -2.6512e-03, -1.3334e-02, -2.3443e-03,\n",
      "         -2.7280e-02,  2.3151e-02, -2.7735e-03,  1.2169e-02,  1.9832e-04],\n",
      "        [-3.1962e-02,  2.4858e-02, -2.3551e-02,  1.2065e-03,  8.5206e-03,\n",
      "          3.5071e-02, -2.7905e-02, -9.3757e-03, -2.1136e-02, -4.6825e-03,\n",
      "         -1.4423e-02,  3.9288e-04,  2.2456e-04,  1.0617e-02,  8.5138e-04,\n",
      "          2.3332e-02, -2.1098e-02,  4.5413e-03, -9.0569e-03,  2.4641e-03],\n",
      "        [-2.2067e-03,  1.8207e-03, -1.6588e-03,  2.5272e-04,  5.5903e-04,\n",
      "          2.5025e-03, -1.9765e-03, -6.6702e-04, -1.4377e-03, -2.7245e-04,\n",
      "         -9.8919e-04,  1.1465e-04,  1.6928e-04,  8.3130e-04,  1.5142e-04,\n",
      "          1.7438e-03, -1.4304e-03,  1.5601e-04, -7.4658e-04, -2.0743e-05],\n",
      "        [-1.3426e-02,  1.0779e-02, -9.9490e-03,  1.9244e-03,  3.4042e-03,\n",
      "          1.4639e-02, -1.1754e-02, -3.8873e-03, -8.6402e-03, -1.9169e-03,\n",
      "         -6.0516e-03,  1.1278e-03,  1.1225e-03,  5.1018e-03,  9.2083e-04,\n",
      "          9.9219e-03, -8.7454e-03,  9.4317e-04, -4.7753e-03, -3.2743e-04],\n",
      "        [-5.1395e-02,  4.0604e-02, -3.8153e-02,  6.8926e-03,  1.3023e-02,\n",
      "          5.5077e-02, -4.4569e-02, -1.4875e-02, -3.3047e-02, -7.6127e-03,\n",
      "         -2.3394e-02,  4.3168e-03,  3.4881e-03,  1.8920e-02,  3.0212e-03,\n",
      "          3.6620e-02, -3.3558e-02,  4.7217e-03, -1.7782e-02,  2.3580e-05],\n",
      "        [ 5.2912e-02, -4.0936e-02,  3.9115e-02, -8.3612e-03, -1.3010e-02,\n",
      "         -5.4530e-02,  4.5053e-02,  1.5045e-02,  3.3622e-02,  8.2963e-03,\n",
      "          2.4380e-02, -5.9194e-03, -3.7225e-03, -1.9401e-02, -3.0433e-03,\n",
      "         -3.5102e-02,  3.4544e-02, -5.1980e-03,  1.8928e-02,  1.7636e-04],\n",
      "        [ 4.3715e-02, -3.5012e-02,  3.2769e-02, -3.5607e-03, -1.1113e-02,\n",
      "         -4.8371e-02,  3.8591e-02,  1.3175e-02,  2.8600e-02,  5.7555e-03,\n",
      "          1.9835e-02, -1.6853e-03, -1.7710e-03, -1.5366e-02, -2.0498e-03,\n",
      "         -3.2721e-02,  2.8513e-02, -4.9270e-03,  1.3618e-02, -1.7746e-03],\n",
      "        [ 6.4997e-02, -5.1598e-02,  4.7348e-02, -7.2997e-03, -1.7694e-02,\n",
      "         -7.1877e-02,  5.6840e-02,  1.8224e-02,  4.2309e-02,  1.0181e-02,\n",
      "          2.8803e-02, -3.8402e-03, -4.5041e-03, -2.4415e-02, -3.9014e-03,\n",
      "         -4.9068e-02,  4.2820e-02, -4.8780e-03,  2.2112e-02,  9.4933e-04],\n",
      "        [-1.6342e-02,  1.3083e-02, -1.2175e-02,  1.4331e-03,  4.2141e-03,\n",
      "          1.8112e-02, -1.4413e-02, -4.8561e-03, -1.0684e-02, -2.2244e-03,\n",
      "         -7.3715e-03,  6.8713e-04,  7.7345e-04,  5.8375e-03,  8.2059e-04,\n",
      "          1.2295e-02, -1.0679e-02,  1.6891e-03, -5.1918e-03,  4.5019e-04]])}, 5: {'momentum_buffer': tensor([-0.0648, -0.0581,  0.0512,  0.0037,  0.0214,  0.0804, -0.0798, -0.0709,\n",
      "        -0.1043,  0.0265])}, 6: {'momentum_buffer': tensor([[-0.0129,  0.0035,  0.0368,  0.0205, -0.0704,  0.0155, -0.0190, -0.0279,\n",
      "         -0.0098,  0.0248],\n",
      "        [ 0.0129, -0.0035, -0.0368, -0.0205,  0.0704, -0.0155,  0.0190,  0.0279,\n",
      "          0.0098, -0.0248]])}, 7: {'momentum_buffer': tensor([ 0.1278, -0.1278])}}\n",
      "param_groups \t [{'lr': 0.001, 'momentum': 0.1, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7]}]\n"
     ]
    }
   ],
   "source": [
    "model# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "510244fed2737faa98f5c507705b781217d54f2f3afb1f6538ba23bbc323ff21"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('nassy-hasler-vBIYXc2u': pipenv)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}