package com.dcap.filters;

import com.dcap.domain.Pythoncode;
import com.dcap.fileReader.DataFile;
import com.dcap.fileReader.DataFileColumn;
import com.dcap.fileReader.DataFileLine;
import com.dcap.fileReader.DataFileUtils;
import com.dcap.service.threads.FilterData;
import com.dcap.domain.Pythoncode;
import com.dcap.fileReader.*;
import com.dcap.service.PythonCodeService;
import com.dcap.service.threads.FilterData;
import com.fasterxml.jackson.databind.ObjectMapper;
import org.python.core.PyObject;
import org.python.util.PythonInterpreter;

import java.io.IOException;
import java.util.*;


/**
 * Class to operate on a file with help of a Pyhton Script (Python2)
 *
 * @author uli
 */
public class CustomizedChangeFilterTemplate extends AbstractChangingFilter {

    /**
     * map of parameters that are needed for the operation. Key is name of paramater, value is the value of the parameter
     * The only mandatory parameter is the id of the filter ("myPythonCode":"<number>")
     * The other paramaters depend on the filter
     */
    private String codeAddress;
    private String parameterAddress;

    /**
     * Constructor of the filter
     * @param code                The data concerning the code and parameter
     * @param columns             map that contains the list of all strings that must be considered, value is the name of the column in the experiment, the
     *                            key is the name of the column in the csv file.
     *                            The key is only a internal name. For setting the parameters, the name of the value is used (it should be the same as in the programm).
     * @param parameter            map of parameters that are needed for the operation. Key is name of paramater, value is the value of the paramete
     *
     */
    public CustomizedChangeFilterTemplate(Pythoncode code, Map<String, String> columns, Map<String, String> parameter) {
        super(code.getName(), columns, parameter);
        this.codeAddress = code.getCodeadress();
        this.parameterAddress = code.getParameteradress();
    }




    /**
     * returns the description of the parameters that are needed as input. Returns the mame of the parameter as key and the type as value
     *
     * @return list of required parameters
     */
    @Override
    public Map<String, ENUMERATED_TYPES> getRequiredParameters() {
        HashMap<String, ENUMERATED_TYPES> parameters = null;
        try {
            parameters = PythonCodeService.getStringENUMERATED_typesHashMap(parameterAddress);
        } catch (IOException e) {
            e.printStackTrace();
        }
        return parameters;
    }

    /**
     * Runs the filter. The filter will get the path to a python script that will do the filtering. The script has two parameters,
     * one parameter is the map that are used for the calcuation (as key is the name that of the list, the value is a list of the values as
     * strings - be aware, must be ASCII), the second parameter is the list ov values. The python script will return a map with the columns after filtering.
     * If the python script returns a name in the map that is not in the original file, it appends a new columnn
     *
     * @param data list of data that should be proceeded
     * @return additional information generated by the filter to be displayed to the user.
     * @throws Exception if something goes wrong
     */
    @Override
    public List<FilterData> run(List<FilterData> data) throws Exception {
        System.err.println("In der CustomFunction");
        data = copyList(data);
        ArrayList<FilterData> returnList = new ArrayList<>();
        for (FilterData filterData : data) {
            DataFile file = filterData.getDataFile();
            ObjectMapper objectMapper = new ObjectMapper();

            Map<String, List<String>> argumentMap = new HashMap<>();


            /*Extracts the columns that are in the columns parameter for the python script. Only the value
            of the map is used, not the key.
             */
            for (Map.Entry<String, String> col : getColumns().entrySet()) {
                DataFileColumn columnn = file.getHeader().getColumn(col.getValue());
                List<String> values = DataFileUtils.getRawValues(file, columnn, true);
                argumentMap.put(col.getValue(), values);
            }

            String arrayJson = objectMapper.writeValueAsString(argumentMap);
            String parameterJson = objectMapper.writeValueAsString(parameter);
            String columns = objectMapper.writeValueAsString(getColumns());
            //System.out.println(s);
            PythonInterpreter interpreter = new PythonInterpreter();
//        interpreter.execfile("/home/uli/Desktop/trash/gs-uploading-files/gradleTest/src/main/java/hallo.py");
//            interpreter.execfile("/home/uli/Desktop/test/hallo2.py");
            interpreter.execfile(codeAddress);
            interpreter.set("arg1", arrayJson);
            interpreter.set("arg2", parameterJson);
            interpreter.set("arg3", columns);
            PyObject eval = interpreter.eval("myPythonClass().execute(arg1, arg2, arg3)");

            /*Gets a json with the columns and the their name. If a name is not the title of a columnname in the datafile,
            a new column is added.
             */
            String json = eval.toString();
            Map map = null;
            try {
                map = objectMapper.readValue(json, Map.class);
            } catch (IOException e) {
                e.printStackTrace();
            }
            /*Hashmap with the calculated values. If the name (key) of an entry is also the name of a header of the datafile, the
            column will be filled with the new values. In all other cases, a new column will be added.
             */
            HashMap<String, List<String>> mapToSet = new HashMap<String, List<String>>(map);
//        String addLines=parameter.get("additional_lines");
//            System.err.println(mapToSet.get("Test"));
//        boolean addLineFlag = addLines != null && !addLines.trim().equals("");
//        String[] split=null;

            String columnsChanged = "";


            /*
            Checks if a new column must be added.
             */
            boolean addLineFlag = false;
            for (String key : mapToSet.keySet()) {
                if (!file.getHeader().hasColumn(key)) {
                    columnsChanged = "; Column Count has changed";
                    file.appendColumn(key);
                    addLineFlag = true;
                }
            }
//            if (addLineFlag) {
//                setColumnsCountChanged(true);
//                split = addLines.split(",");
//                for (String newColumnName : split) {
//                    file.appendColumn(newColumnName);
//                }
//
//            }
            Iterator<DataFileLine> iterator = file.getContent().iterator();
            int index = 0;
            while (iterator.hasNext()) {
                DataFileLine line = iterator.next();
                for (String col : mapToSet.keySet()) {
                    DataFileColumn column = file.getHeader().getColumn(col);
                    List<String> strings = mapToSet.get(col);
                    String value = strings.get(index);
                    line.setValue(column, value);
                }
//                if (addLineFlag) {
//                    for (String col : split) {
//                        DataFileColumn column = file.getHeader().getColumn(col);
//                        List<String> strings = mapToSet.get(col);
//                        String value = strings.get(index);
//                        line.setValue(column, value);
//                    }
//                }

                index++;
            }

            String returnMessage = getName() + columnsChanged;

            FilterData filterData1 = new FilterData(file, filterData.getName(), filterData.getUserData(), filterData.getMessage() + "; " + returnMessage);
            returnList.add(filterData1);
        }
        return returnList;
    }
}
